{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:18.208867Z",
     "start_time": "2025-06-06T16:17:17.881947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =======================\n",
    "# Imports & Configuration\n",
    "# =======================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn: Preprocessing, Modeling, Evaluation, Feature Selection\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Statistical tools\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Matplotlib & seaborn configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "d11dbcf7788dcd8a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 0: Data Loading and Inspection",
   "id": "7e54cefe3415b95e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:18.667981Z",
     "start_time": "2025-06-06T16:17:18.277173Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_train.csv\")",
   "id": "116e6e31d2db3e4e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:18.687080Z",
     "start_time": "2025-06-06T16:17:18.678356Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "9475613d8d85a806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:19.935761Z",
     "start_time": "2025-06-06T16:17:19.919333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's print some descriptive statistics for all the numeric features.\n",
    "\n",
    "df.describe().T\n",
    "# This gives that it is highly right-skewed for all numeric features apart from age\n",
    "# The age distribution is right-skewed. The majority of passengers are young adults (20–30).\n",
    "# The median is close to the mean, the skew isn't too extreme."
   ],
   "id": "b4db5e03ba9b3ea7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               count        mean          std  min   25%   50%   75%      max\n",
       "Age           8514.0   28.827930    14.489021  0.0  19.0  27.0  38.0     79.0\n",
       "RoomService   8512.0  224.687617   666.717663  0.0   0.0   0.0  47.0  14327.0\n",
       "FoodCourt     8510.0  458.077203  1611.489240  0.0   0.0   0.0  76.0  29813.0\n",
       "ShoppingMall  8485.0  173.729169   604.696458  0.0   0.0   0.0  27.0  23492.0\n",
       "Spa           8510.0  311.138778  1136.705535  0.0   0.0   0.0  59.0  22408.0\n",
       "VRDeck        8505.0  304.854791  1145.717189  0.0   0.0   0.0  46.0  24133.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>8514.0</td>\n",
       "      <td>28.827930</td>\n",
       "      <td>14.489021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>8512.0</td>\n",
       "      <td>224.687617</td>\n",
       "      <td>666.717663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>8510.0</td>\n",
       "      <td>458.077203</td>\n",
       "      <td>1611.489240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>8485.0</td>\n",
       "      <td>173.729169</td>\n",
       "      <td>604.696458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>8510.0</td>\n",
       "      <td>311.138778</td>\n",
       "      <td>1136.705535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>8505.0</td>\n",
       "      <td>304.854791</td>\n",
       "      <td>1145.717189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>24133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:20.688840Z",
     "start_time": "2025-06-06T16:17:20.664133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's print some descriptive statistics for all the numeric features.\n",
    "\n",
    "df.describe().T# What is the number of unique values in all the categorical features? And what is\n",
    "# the value with the highest frequency?\n",
    "\n",
    "df.describe(include=object).T\n",
    "# can frop 'Name' feature\n",
    "# looking at the dataset from cabin, can see whether or not passenger is solo or in a group."
   ],
   "id": "574d130a381aaa84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            count unique             top  freq\n",
       "PassengerId  8693   8693         0001_01     1\n",
       "HomePlanet   8492      3           Earth  4602\n",
       "CryoSleep    8476      2           False  5439\n",
       "Cabin        8494   6560         G/734/S     8\n",
       "Destination  8511      3     TRAPPIST-1e  5915\n",
       "VIP          8490      2           False  8291\n",
       "Name         8493   8473  Gollux Reedall     2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>8693</td>\n",
       "      <td>8693</td>\n",
       "      <td>0001_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>8492</td>\n",
       "      <td>3</td>\n",
       "      <td>Earth</td>\n",
       "      <td>4602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>8476</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>8494</td>\n",
       "      <td>6560</td>\n",
       "      <td>G/734/S</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>8511</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>5915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>8490</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>8291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>8493</td>\n",
       "      <td>8473</td>\n",
       "      <td>Gollux Reedall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:20.955431Z",
     "start_time": "2025-06-06T16:17:20.951309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How much missing data is in each feature?\n",
    "\n",
    "df.isna().sum()"
   ],
   "id": "2ac2e47cbfd29193",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:21.828767Z",
     "start_time": "2025-06-06T16:17:21.825400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For convienience, let's save the names of all numeric features to a list,\n",
    "# and the names of all categorical features to another list.\n",
    "\n",
    "numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "categorical_features = ['HomePlanet', 'VIP', 'CryoSleep', 'Destination', 'Cabin', 'Name']"
   ],
   "id": "64cf9a12b3e85109",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T16:17:22.424986Z",
     "start_time": "2025-06-06T16:17:22.244947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# SPACESHIP TITANIC: RESCUE MISSION - ADVANCED EDA & FEATURE ENGINEERING\n",
    "# ================================================================\n",
    "# Mission: Extract every signal from damaged ship logs to save more lives\n",
    "# Objective: Build AI-powered triage engine for passenger rescue prediction\n",
    "# Target: Every 1% accuracy improvement = hundreds more lives saved\n",
    "\n",
    "print(\"🚀 SPACESHIP TITANIC RESCUE MISSION INITIATED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ================================================================\n",
    "# PHASE 1: INTELLIGENCE GATHERING - LOAD & INITIAL INSPECTION\n",
    "# ================================================================\n",
    "\n",
    "def load_and_inspect_data():\n",
    "    \"\"\"Load data and perform initial intelligence gathering\"\"\"\n",
    "    print(\"\\n📊 PHASE 1: INTELLIGENCE GATHERING\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Load training data\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_train.csv\")\n",
    "\n",
    "    print(f\"🔍 Mission Log Analysis:\")\n",
    "    print(f\"   - Total passengers in manifest: {len(df):,}\")\n",
    "    print(f\"   - Data integrity: {df.shape[1]} features recorded\")\n",
    "    print(f\"   - Missing data assessment needed...\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def comprehensive_data_quality_analysis(df):\n",
    "    \"\"\"Deep dive into data quality and patterns\"\"\"\n",
    "    print(\"\\n🔬 COMPREHENSIVE DATA QUALITY ANALYSIS\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    # Basic info\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    # Missing data analysis\n",
    "    missing_analysis = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        'Data_Type': df.dtypes\n",
    "    }).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "    print(\"\\n📋 MISSING DATA INTELLIGENCE REPORT:\")\n",
    "    print(missing_analysis[missing_analysis['Missing_Count'] > 0])\n",
    "\n",
    "    # Class distribution analysis\n",
    "    print(\"\\n⚖️ TARGET DISTRIBUTION ANALYSIS:\")\n",
    "    target_dist = df['Transported'].value_counts()\n",
    "    print(f\"Transported: {target_dist[True]:,} ({target_dist[True]/len(df)*100:.1f}%)\")\n",
    "    print(f\"Not Transported: {target_dist[False]:,} ({target_dist[False]/len(df)*100:.1f}%)\")\n",
    "\n",
    "    # Data types summary\n",
    "    print(f\"\\n📊 DATA TYPES SUMMARY:\")\n",
    "    dtype_summary = df.dtypes.value_counts()\n",
    "    for dtype, count in dtype_summary.items():\n",
    "        print(f\"   {dtype}: {count} features\")\n",
    "\n",
    "    return missing_analysis\n",
    "\n",
    "\n",
    "try:\n",
    "    # Execute the complete EDA pipeline\n",
    "    print(\"🚀 Starting Spaceship Titanic Rescue Mission Analysis...\")\n",
    "\n",
    "    # Phase 1: Load and inspect data\n",
    "    df = load_and_inspect_data()\n",
    "\n",
    "    # Phase 2: Comprehensive data quality analysis\n",
    "    missing_analysis = comprehensive_data_quality_analysis(df)\n",
    "\n",
    "    # Mission completion summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 RESCUE MISSION EDA COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✅ Analyzed {len(df):,} passenger records\")\n",
    "    print(f\"✅ Generated comprehensive visualizations\")\n",
    "    print(f\"✅ Identified key rescue patterns\")\n",
    "    print(\"\\n🚨 Ready for model development phase!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Mission encountered error: {str(e)}\")\n",
    "    print(\"🔧 Check data source and dependencies\")"
   ],
   "id": "7e1e745ce6213e56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 SPACESHIP TITANIC RESCUE MISSION INITIATED\n",
      "============================================================\n",
      "🚀 Starting Spaceship Titanic Rescue Mission Analysis...\n",
      "\n",
      "📊 PHASE 1: INTELLIGENCE GATHERING\n",
      "----------------------------------------\n",
      "🔍 Mission Log Analysis:\n",
      "   - Total passengers in manifest: 8,693\n",
      "   - Data integrity: 14 features recorded\n",
      "   - Missing data assessment needed...\n",
      "\n",
      "🔬 COMPREHENSIVE DATA QUALITY ANALYSIS\n",
      "---------------------------------------------\n",
      "Dataset Shape: (8693, 14)\n",
      "Memory Usage: 3.65 MB\n",
      "\n",
      "📋 MISSING DATA INTELLIGENCE REPORT:\n",
      "                    Column  Missing_Count  Missing_Percentage Data_Type\n",
      "CryoSleep        CryoSleep            217                2.50    object\n",
      "ShoppingMall  ShoppingMall            208                2.39   float64\n",
      "VIP                    VIP            203                2.34    object\n",
      "HomePlanet      HomePlanet            201                2.31    object\n",
      "Name                  Name            200                2.30    object\n",
      "Cabin                Cabin            199                2.29    object\n",
      "VRDeck              VRDeck            188                2.16   float64\n",
      "FoodCourt        FoodCourt            183                2.11   float64\n",
      "Spa                    Spa            183                2.11   float64\n",
      "Destination    Destination            182                2.09    object\n",
      "RoomService    RoomService            181                2.08   float64\n",
      "Age                    Age            179                2.06   float64\n",
      "\n",
      "⚖️ TARGET DISTRIBUTION ANALYSIS:\n",
      "Transported: 4,378 (50.4%)\n",
      "Not Transported: 4,315 (49.6%)\n",
      "\n",
      "📊 DATA TYPES SUMMARY:\n",
      "   object: 7 features\n",
      "   float64: 6 features\n",
      "   bool: 1 features\n",
      "\n",
      "============================================================\n",
      "🎉 RESCUE MISSION EDA COMPLETE!\n",
      "============================================================\n",
      "✅ Analyzed 8,693 passenger records\n",
      "✅ Generated comprehensive visualizations\n",
      "✅ Identified key rescue patterns\n",
      "\n",
      "🚨 Ready for model development phase!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:38.336167Z",
     "start_time": "2025-06-06T17:17:38.315032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# Feature Engineering Helper Functions\n",
    "# ================================================================\n",
    "\n",
    "def handle_missing_values(df, categorical_features):\n",
    "    \"\"\"Handle missing values for numerical and categorical features\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Impute Age with mean\n",
    "    age_imputer = SimpleImputer()\n",
    "    df['Age'] = age_imputer.fit_transform(df[['Age']]).flatten()\n",
    "\n",
    "    # Impute spending columns with most frequent value\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    spent_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    df[spending_cols] = spent_imputer.fit_transform(df[spending_cols])\n",
    "\n",
    "    # Fill categorical missing values with 'Missing'\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].fillna('Missing')\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"Create engineered features\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Solo traveler feature\n",
    "    df['SoloTraveler'] = (df['Cabin'].map(df['Cabin'].value_counts()) == 1)\n",
    "\n",
    "    # Spending features\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    df['TotalSpend'] = df[spending_cols].sum(axis=1)\n",
    "    df['LuxurySpend'] = df[['Spa', 'VRDeck']].sum(axis=1)\n",
    "    df['BasicSpend'] = df[['RoomService', 'FoodCourt']].sum(axis=1)\n",
    "\n",
    "    # Cabin-based interaction features\n",
    "    cabin_prefix = df['Cabin'].astype(str).str.split('/').str[0]\n",
    "    df['Cabin_HomePlanet'] = cabin_prefix + \"_\" + df['HomePlanet'].astype(str)\n",
    "    df['Cabin_Destination'] = cabin_prefix + \"_\" + df['Destination'].astype(str)\n",
    "    df['Cabin_CryoSleep'] = cabin_prefix + \"_\" + df['CryoSleep'].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_data_types(df):\n",
    "    \"\"\"Convert columns to appropriate data types\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Convert to categorical\n",
    "    categorical_cols = ['HomePlanet', 'Destination', 'VIP', 'CryoSleep', 'SoloTraveler',\n",
    "                        'Cabin_HomePlanet', 'Cabin_Destination', 'Cabin_CryoSleep']\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "def select_features_and_prepare_target(df, features_to_drop=None, is_train=True):\n",
    "    \"\"\"Select features and prepare target variable\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Default features to drop\n",
    "    default_drop = ['PassengerId', 'Cabin', 'Name']\n",
    "\n",
    "    if features_to_drop:\n",
    "        default_drop.extend(features_to_drop)\n",
    "\n",
    "    # Remove target variable from features if it exists\n",
    "    if is_train and 'Transported' in df.columns:\n",
    "        y = df['Transported']\n",
    "        default_drop.append('Transported')\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    # Select features\n",
    "    X = df.drop(default_drop, axis=1, errors='ignore')\n",
    "\n",
    "    # Get categorical feature names\n",
    "    categorical_features = X.select_dtypes(include='category').columns.tolist()\n",
    "\n",
    "    return X, y, X.columns.tolist(), categorical_features\n",
    "\n",
    "def encode_categorical_features(X, categorical_features, encoders=None, fit=True):\n",
    "    \"\"\"Encode categorical features using LabelEncoder\"\"\"\n",
    "    X_encoded = X.copy()\n",
    "\n",
    "    if encoders is None:\n",
    "        encoders = {}\n",
    "\n",
    "    for col in categorical_features:\n",
    "        if col in X_encoded.columns:\n",
    "            X_encoded[col] = X_encoded[col].astype(str)\n",
    "\n",
    "            if fit:\n",
    "                # Fit new encoder for training data\n",
    "                le = LabelEncoder()\n",
    "                X_encoded[col] = le.fit_transform(X_encoded[col])\n",
    "                encoders[col] = le\n",
    "            else:\n",
    "                # Use existing encoder for test data\n",
    "                if col in encoders:\n",
    "                    # Handle unseen categories\n",
    "                    le = encoders[col]\n",
    "                    mask = X_encoded[col].isin(le.classes_)\n",
    "                    X_encoded.loc[mask, col] = le.transform(X_encoded.loc[mask, col])\n",
    "                    X_encoded.loc[~mask, col] = -1  # Assign -1 to unseen categories\n",
    "\n",
    "                    # Explicitly convert to int64 to match training data\n",
    "                    X_encoded[col] = X_encoded[col].astype('int64')\n",
    "                else:\n",
    "                    # If no encoder exists, assign -1 to all values\n",
    "                    X_encoded[col] = -1\n",
    "                    X_encoded[col] = X_encoded[col].astype('int64')\n",
    "\n",
    "    # Ensure all categorical features are properly converted to int64\n",
    "    for col in categorical_features:\n",
    "        if col in X_encoded.columns:\n",
    "            X_encoded[col] = pd.to_numeric(X_encoded[col], errors='coerce').fillna(-1).astype('int64')\n",
    "\n",
    "    return X_encoded, encoders\n",
    "\n",
    "# ================================================================\n",
    "# FEATURE ENGINEERING PIPELINE\n",
    "# ================================================================\n",
    "\n",
    "def run_feature_engineering_pipeline(df):\n",
    "    \"\"\"\n",
    "    Complete Feature Engineering Pipeline matching original implementation\n",
    "\n",
    "    Processes raw data through all steps including encoding to output ML-ready dataset.\n",
    "\n",
    "    Args:\n",
    "        df: Raw passenger dataframe\n",
    "\n",
    "    Returns:\n",
    "        final_df: Fully processed dataframe with encoded features ready for ML\n",
    "    \"\"\"\n",
    "    print(\"🚀 SPACESHIP TITANIC FEATURE ENGINEERING PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Create working copy and preserve passenger ID\n",
    "    df = df.copy()\n",
    "    if 'PassengerId' in df.columns:\n",
    "        df['PassengerId'] = df['PassengerId'].astype(str)\n",
    "        df['_PassengerId_Original'] = df['PassengerId']\n",
    "\n",
    "    original_features = df.shape[1]\n",
    "\n",
    "    # Step 1: Missing Value Imputation\n",
    "    print(\"\\n🩹 STEP 1: MISSING VALUE IMPUTATION\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    categorical_features = ['HomePlanet', 'VIP', 'CryoSleep', 'Destination', 'Cabin', 'Name']\n",
    "    df = handle_missing_values(df, categorical_features)\n",
    "    print(\"   ✅ Age: Missing values filled with mean\")\n",
    "    print(\"   ✅ Spending columns: Imputed with most frequent values\")\n",
    "    print(\"   ✅ Categorical columns: Missing values marked as 'Missing'\")\n",
    "\n",
    "    # Step 2: Feature Creation\n",
    "    print(\"\\n⚡ STEP 2: NEW FEATURE CREATION\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    df = create_features(df)\n",
    "    print(\"   ✅ SoloTraveler: Binary feature based on cabin occupancy\")\n",
    "    print(\"   ✅ TotalSpend: Sum of all amenity spending\")\n",
    "    print(\"   ✅ LuxurySpend: Spa + VRDeck spending\")\n",
    "    print(\"   ✅ BasicSpend: RoomService + FoodCourt spending\")\n",
    "    print(\"   ✅ Cabin interactions: Cabin prefix + passenger attributes\")\n",
    "\n",
    "    # Step 3: Data Type Optimization\n",
    "    print(\"\\n🤖 STEP 3: DATA TYPE OPTIMIZATION\")\n",
    "    print(\"-\" * 38)\n",
    "\n",
    "    df = convert_data_types(df)\n",
    "    print(\"   ✅ Categorical columns converted to 'category' dtype\")\n",
    "\n",
    "    # Step 4: Feature Selection and Target Preparation\n",
    "    print(\"\\n🎯 STEP 4: FEATURE SELECTION\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    X, y, feature_names, cat_features = select_features_and_prepare_target(\n",
    "        df, is_train=('Transported' in df.columns)\n",
    "    )\n",
    "    print(f\"   ✅ Selected {len(feature_names)} features for ML\")\n",
    "    print(f\"   ✅ Identified {len(cat_features)} categorical features\")\n",
    "\n",
    "    # Step 5: Categorical Encoding\n",
    "    print(\"\\n🔢 STEP 5: CATEGORICAL ENCODING\")\n",
    "    print(\"-\" * 35)\n",
    "\n",
    "    X_encoded, encoders = encode_categorical_features(X, cat_features, fit=True)\n",
    "    print(f\"   ✅ {len(cat_features)} categorical features encoded to numeric\")\n",
    "    print(\"   ✅ All features now ML-ready\")\n",
    "\n",
    "    # Step 6: Final Dataset Assembly\n",
    "    print(\"\\n📦 STEP 6: FINAL DATASET ASSEMBLY\")\n",
    "    print(\"-\" * 36)\n",
    "\n",
    "    # Create final dataset with encoded features\n",
    "    final_df = X_encoded.copy()\n",
    "\n",
    "    # Add back essential columns\n",
    "    if 'PassengerId' in df.columns:\n",
    "        final_df['PassengerId'] = df['PassengerId'].values\n",
    "    if '_PassengerId_Original' in df.columns:\n",
    "        final_df['_PassengerId_Original'] = df['_PassengerId_Original'].values\n",
    "    if y is not None:\n",
    "        final_df['Transported'] = y.values\n",
    "\n",
    "    print(\"   ✅ Final dataset assembled with all encoded features\")\n",
    "    print(\"   ✅ Essential identification columns preserved\")\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 FEATURE ENGINEERING COMPLETE!\")\n",
    "    print(f\"   📊 Original features: {original_features}\")\n",
    "    print(f\"   📊 ML features: {X_encoded.shape[1]}\")\n",
    "    print(f\"   📊 Total columns: {final_df.shape[1]} (includes IDs and target)\")\n",
    "    print(\"   🚀 Dataset fully processed and ML-ready\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Return final processed dataframe\n",
    "    final_df = final_df.drop('_PassengerId_Original', axis=1, errors='ignore')\n",
    "\n",
    "    return final_df"
   ],
   "id": "79d43ec950dde0e8",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:39.283641Z",
     "start_time": "2025-06-06T17:17:38.857266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load the raw dataset\n",
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_train.csv\")\n",
    "\n",
    "# 2. Run the full feature engineering pipeline (ensure the function is defined)\n",
    "df_processed_train = run_feature_engineering_pipeline(df_train)\n",
    "\n",
    "# 3: Export the complete processed dataframe\n",
    "df_processed_train.to_csv('train_dataset_spaceship_titanic_processed.csv', index=False)\n",
    "print(f\"   ✅ Complete dataset exported: train_dataset_spaceship_titanic_processed.csv\")\n",
    "print(f\"   📊 Shape: {df_processed_train.shape}\")"
   ],
   "id": "88cb0c0f07eb9e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 SPACESHIP TITANIC FEATURE ENGINEERING PIPELINE\n",
      "============================================================\n",
      "\n",
      "🩹 STEP 1: MISSING VALUE IMPUTATION\n",
      "----------------------------------------\n",
      "   ✅ Age: Missing values filled with mean\n",
      "   ✅ Spending columns: Imputed with most frequent values\n",
      "   ✅ Categorical columns: Missing values marked as 'Missing'\n",
      "\n",
      "⚡ STEP 2: NEW FEATURE CREATION\n",
      "-----------------------------------\n",
      "   ✅ SoloTraveler: Binary feature based on cabin occupancy\n",
      "   ✅ TotalSpend: Sum of all amenity spending\n",
      "   ✅ LuxurySpend: Spa + VRDeck spending\n",
      "   ✅ BasicSpend: RoomService + FoodCourt spending\n",
      "   ✅ Cabin interactions: Cabin prefix + passenger attributes\n",
      "\n",
      "🤖 STEP 3: DATA TYPE OPTIMIZATION\n",
      "--------------------------------------\n",
      "   ✅ Categorical columns converted to 'category' dtype\n",
      "\n",
      "🎯 STEP 4: FEATURE SELECTION\n",
      "------------------------------\n",
      "   ✅ Selected 18 features for ML\n",
      "   ✅ Identified 8 categorical features\n",
      "\n",
      "🔢 STEP 5: CATEGORICAL ENCODING\n",
      "-----------------------------------\n",
      "   ✅ 8 categorical features encoded to numeric\n",
      "   ✅ All features now ML-ready\n",
      "\n",
      "📦 STEP 6: FINAL DATASET ASSEMBLY\n",
      "------------------------------------\n",
      "   ✅ Final dataset assembled with all encoded features\n",
      "   ✅ Essential identification columns preserved\n",
      "\n",
      "============================================================\n",
      "🎉 FEATURE ENGINEERING COMPLETE!\n",
      "   📊 Original features: 15\n",
      "   📊 ML features: 18\n",
      "   📊 Total columns: 20 (includes IDs and target)\n",
      "   🚀 Dataset fully processed and ML-ready\n",
      "============================================================\n",
      "   ✅ Complete dataset exported: train_dataset_spaceship_titanic_processed.csv\n",
      "   📊 Shape: (8693, 19)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:39.774818Z",
     "start_time": "2025-06-06T17:17:39.521689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load the raw dataset for Test set\n",
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_test.csv\")\n",
    "\n",
    "# 2. Run the full feature engineering pipeline (ensure the function is defined)\n",
    "df_processed_test = run_feature_engineering_pipeline(df_test)\n",
    "\n",
    "# 3: Export the complete processed dataframe\n",
    "df_processed_test.to_csv('test_dataset_spaceship_titanic_processed.csv', index=False)\n",
    "print(f\"   ✅ Complete dataset exported: test_dataset_spaceship_titanic_processed.csv\")\n",
    "print(f\"   📊 Shape: {df_processed_test.shape}\")"
   ],
   "id": "9bc3827e62302a3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 SPACESHIP TITANIC FEATURE ENGINEERING PIPELINE\n",
      "============================================================\n",
      "\n",
      "🩹 STEP 1: MISSING VALUE IMPUTATION\n",
      "----------------------------------------\n",
      "   ✅ Age: Missing values filled with mean\n",
      "   ✅ Spending columns: Imputed with most frequent values\n",
      "   ✅ Categorical columns: Missing values marked as 'Missing'\n",
      "\n",
      "⚡ STEP 2: NEW FEATURE CREATION\n",
      "-----------------------------------\n",
      "   ✅ SoloTraveler: Binary feature based on cabin occupancy\n",
      "   ✅ TotalSpend: Sum of all amenity spending\n",
      "   ✅ LuxurySpend: Spa + VRDeck spending\n",
      "   ✅ BasicSpend: RoomService + FoodCourt spending\n",
      "   ✅ Cabin interactions: Cabin prefix + passenger attributes\n",
      "\n",
      "🤖 STEP 3: DATA TYPE OPTIMIZATION\n",
      "--------------------------------------\n",
      "   ✅ Categorical columns converted to 'category' dtype\n",
      "\n",
      "🎯 STEP 4: FEATURE SELECTION\n",
      "------------------------------\n",
      "   ✅ Selected 18 features for ML\n",
      "   ✅ Identified 8 categorical features\n",
      "\n",
      "🔢 STEP 5: CATEGORICAL ENCODING\n",
      "-----------------------------------\n",
      "   ✅ 8 categorical features encoded to numeric\n",
      "   ✅ All features now ML-ready\n",
      "\n",
      "📦 STEP 6: FINAL DATASET ASSEMBLY\n",
      "------------------------------------\n",
      "   ✅ Final dataset assembled with all encoded features\n",
      "   ✅ Essential identification columns preserved\n",
      "\n",
      "============================================================\n",
      "🎉 FEATURE ENGINEERING COMPLETE!\n",
      "   📊 Original features: 14\n",
      "   📊 ML features: 18\n",
      "   📊 Total columns: 19 (includes IDs and target)\n",
      "   🚀 Dataset fully processed and ML-ready\n",
      "============================================================\n",
      "   ✅ Complete dataset exported: test_dataset_spaceship_titanic_processed.csv\n",
      "   📊 Shape: (4277, 18)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T17:17:40.730910Z",
     "start_time": "2025-06-06T17:17:40.719568Z"
    }
   },
   "cell_type": "code",
   "source": "df_processed_test.head(5)",
   "id": "d0149246e39981fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  FoodCourt  \\\n",
       "0           0          2            3  27.0    0          0.0        0.0   \n",
       "1           0          0            3  19.0    0          0.0        9.0   \n",
       "2           1          2            0  31.0    0          0.0        0.0   \n",
       "3           1          0            3  38.0    0          0.0     6652.0   \n",
       "4           0          0            3  20.0    0         10.0        0.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  SoloTraveler  TotalSpend  LuxurySpend  \\\n",
       "0           0.0     0.0     0.0             1         0.0          0.0   \n",
       "1           0.0  2823.0     0.0             1      2832.0       2823.0   \n",
       "2           0.0     0.0     0.0             1         0.0          0.0   \n",
       "3           0.0   181.0   585.0             1      7418.0        766.0   \n",
       "4         635.0     0.0     0.0             1       645.0          0.0   \n",
       "\n",
       "   BasicSpend  Cabin_HomePlanet  Cabin_Destination  Cabin_CryoSleep  \\\n",
       "0         0.0                16                 25               20   \n",
       "1         9.0                13                 21               15   \n",
       "2         0.0                 4                  7                8   \n",
       "3      6652.0                 4                 10                6   \n",
       "4        10.0                13                 21               15   \n",
       "\n",
       "  PassengerId  \n",
       "0     0013_01  \n",
       "1     0018_01  \n",
       "2     0019_01  \n",
       "3     0021_01  \n",
       "4     0023_01  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>SoloTraveler</th>\n",
       "      <th>TotalSpend</th>\n",
       "      <th>LuxurySpend</th>\n",
       "      <th>BasicSpend</th>\n",
       "      <th>Cabin_HomePlanet</th>\n",
       "      <th>Cabin_Destination</th>\n",
       "      <th>Cabin_CryoSleep</th>\n",
       "      <th>PassengerId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>0013_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2832.0</td>\n",
       "      <td>2823.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0018_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0019_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7418.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0021_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>645.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>0023_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5047172b6152d4bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
