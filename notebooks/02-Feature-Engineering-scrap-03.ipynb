{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:18.465333Z",
     "start_time": "2025-06-06T23:58:18.113344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =======================\n",
    "# Imports & Configuration\n",
    "# =======================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn: Preprocessing, Modeling, Evaluation, Feature Selection\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, VarianceThreshold\n",
    "\n",
    "# Statistical tools\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Matplotlib & seaborn configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n"
   ],
   "id": "d11dbcf7788dcd8a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 0: Data Loading and Inspection",
   "id": "7e54cefe3415b95e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:18.741724Z",
     "start_time": "2025-06-06T23:58:18.473377Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_train.csv\")",
   "id": "116e6e31d2db3e4e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:18.824445Z",
     "start_time": "2025-06-06T23:58:18.816979Z"
    }
   },
   "cell_type": "code",
   "source": "df.info()",
   "id": "9475613d8d85a806",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      " 13  Transported   8693 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 891.5+ KB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:18.906159Z",
     "start_time": "2025-06-06T23:58:18.895049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's print some descriptive statistics for all the numeric features.\n",
    "\n",
    "df.describe().T\n",
    "# This gives that it is highly right-skewed for all numeric features apart from age\n",
    "# The age distribution is right-skewed. The majority of passengers are young adults (20–30).\n",
    "# The median is close to the mean, the skew isn't too extreme."
   ],
   "id": "b4db5e03ba9b3ea7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               count        mean          std  min   25%   50%   75%      max\n",
       "Age           8514.0   28.827930    14.489021  0.0  19.0  27.0  38.0     79.0\n",
       "RoomService   8512.0  224.687617   666.717663  0.0   0.0   0.0  47.0  14327.0\n",
       "FoodCourt     8510.0  458.077203  1611.489240  0.0   0.0   0.0  76.0  29813.0\n",
       "ShoppingMall  8485.0  173.729169   604.696458  0.0   0.0   0.0  27.0  23492.0\n",
       "Spa           8510.0  311.138778  1136.705535  0.0   0.0   0.0  59.0  22408.0\n",
       "VRDeck        8505.0  304.854791  1145.717189  0.0   0.0   0.0  46.0  24133.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>8514.0</td>\n",
       "      <td>28.827930</td>\n",
       "      <td>14.489021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RoomService</th>\n",
       "      <td>8512.0</td>\n",
       "      <td>224.687617</td>\n",
       "      <td>666.717663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>14327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FoodCourt</th>\n",
       "      <td>8510.0</td>\n",
       "      <td>458.077203</td>\n",
       "      <td>1611.489240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29813.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ShoppingMall</th>\n",
       "      <td>8485.0</td>\n",
       "      <td>173.729169</td>\n",
       "      <td>604.696458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spa</th>\n",
       "      <td>8510.0</td>\n",
       "      <td>311.138778</td>\n",
       "      <td>1136.705535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VRDeck</th>\n",
       "      <td>8505.0</td>\n",
       "      <td>304.854791</td>\n",
       "      <td>1145.717189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>24133.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:18.974148Z",
     "start_time": "2025-06-06T23:58:18.955805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's print some descriptive statistics for all the numeric features.\n",
    "\n",
    "df.describe().T# What is the number of unique values in all the categorical features? And what is\n",
    "# the value with the highest frequency?\n",
    "\n",
    "df.describe(include=object).T\n",
    "# can frop 'Name' feature\n",
    "# looking at the dataset from cabin, can see whether or not passenger is solo or in a group."
   ],
   "id": "574d130a381aaa84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            count unique             top  freq\n",
       "PassengerId  8693   8693         0001_01     1\n",
       "HomePlanet   8492      3           Earth  4602\n",
       "CryoSleep    8476      2           False  5439\n",
       "Cabin        8494   6560         G/734/S     8\n",
       "Destination  8511      3     TRAPPIST-1e  5915\n",
       "VIP          8490      2           False  8291\n",
       "Name         8493   8473  Gollux Reedall     2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>8693</td>\n",
       "      <td>8693</td>\n",
       "      <td>0001_01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HomePlanet</th>\n",
       "      <td>8492</td>\n",
       "      <td>3</td>\n",
       "      <td>Earth</td>\n",
       "      <td>4602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CryoSleep</th>\n",
       "      <td>8476</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>8494</td>\n",
       "      <td>6560</td>\n",
       "      <td>G/734/S</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Destination</th>\n",
       "      <td>8511</td>\n",
       "      <td>3</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>5915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIP</th>\n",
       "      <td>8490</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>8291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>8493</td>\n",
       "      <td>8473</td>\n",
       "      <td>Gollux Reedall</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:19.126241Z",
     "start_time": "2025-06-06T23:58:19.121456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# How much missing data is in each feature?\n",
    "\n",
    "df.isna().sum()"
   ],
   "id": "2ac2e47cbfd29193",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId       0\n",
       "HomePlanet      201\n",
       "CryoSleep       217\n",
       "Cabin           199\n",
       "Destination     182\n",
       "Age             179\n",
       "VIP             203\n",
       "RoomService     181\n",
       "FoodCourt       183\n",
       "ShoppingMall    208\n",
       "Spa             183\n",
       "VRDeck          188\n",
       "Name            200\n",
       "Transported       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:19.968555Z",
     "start_time": "2025-06-06T23:58:19.965691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For convienience, let's save the names of all numeric features to a list,\n",
    "# and the names of all categorical features to another list.\n",
    "\n",
    "numeric_features = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "categorical_features = ['HomePlanet', 'VIP', 'CryoSleep', 'Destination', 'Cabin', 'Name']"
   ],
   "id": "64cf9a12b3e85109",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:21.060966Z",
     "start_time": "2025-06-06T23:58:20.812460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# SPACESHIP TITANIC: RESCUE MISSION - ADVANCED EDA & FEATURE ENGINEERING\n",
    "# ================================================================\n",
    "# Mission: Extract every signal from damaged ship logs to save more lives\n",
    "# Objective: Build AI-powered triage engine for passenger rescue prediction\n",
    "# Target: Every 1% accuracy improvement = hundreds more lives saved\n",
    "\n",
    "print(\"🚀 SPACESHIP TITANIC RESCUE MISSION INITIATED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ================================================================\n",
    "# PHASE 1: INTELLIGENCE GATHERING - LOAD & INITIAL INSPECTION\n",
    "# ================================================================\n",
    "\n",
    "def load_and_inspect_data():\n",
    "    \"\"\"Load data and perform initial intelligence gathering\"\"\"\n",
    "    print(\"\\n📊 PHASE 1: INTELLIGENCE GATHERING\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # Load training data\n",
    "    df = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_train.csv\")\n",
    "\n",
    "    print(f\"🔍 Mission Log Analysis:\")\n",
    "    print(f\"   - Total passengers in manifest: {len(df):,}\")\n",
    "    print(f\"   - Data integrity: {df.shape[1]} features recorded\")\n",
    "    print(f\"   - Missing data assessment needed...\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def comprehensive_data_quality_analysis(df):\n",
    "    \"\"\"Deep dive into data quality and patterns\"\"\"\n",
    "    print(\"\\n🔬 COMPREHENSIVE DATA QUALITY ANALYSIS\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    # Basic info\n",
    "    print(f\"Dataset Shape: {df.shape}\")\n",
    "    print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    # Missing data analysis\n",
    "    missing_analysis = pd.DataFrame({\n",
    "        'Column': df.columns,\n",
    "        'Missing_Count': df.isnull().sum(),\n",
    "        'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2),\n",
    "        'Data_Type': df.dtypes\n",
    "    }).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "    print(\"\\n📋 MISSING DATA INTELLIGENCE REPORT:\")\n",
    "    print(missing_analysis[missing_analysis['Missing_Count'] > 0])\n",
    "\n",
    "    # Class distribution analysis\n",
    "    print(\"\\n⚖️ TARGET DISTRIBUTION ANALYSIS:\")\n",
    "    target_dist = df['Transported'].value_counts()\n",
    "    print(f\"Transported: {target_dist[True]:,} ({target_dist[True]/len(df)*100:.1f}%)\")\n",
    "    print(f\"Not Transported: {target_dist[False]:,} ({target_dist[False]/len(df)*100:.1f}%)\")\n",
    "\n",
    "    # Data types summary\n",
    "    print(f\"\\n📊 DATA TYPES SUMMARY:\")\n",
    "    dtype_summary = df.dtypes.value_counts()\n",
    "    for dtype, count in dtype_summary.items():\n",
    "        print(f\"   {dtype}: {count} features\")\n",
    "\n",
    "    return missing_analysis\n",
    "\n",
    "\n",
    "try:\n",
    "    # Execute the complete EDA pipeline\n",
    "    print(\"🚀 Starting Spaceship Titanic Rescue Mission Analysis...\")\n",
    "\n",
    "    # Phase 1: Load and inspect data\n",
    "    df = load_and_inspect_data()\n",
    "\n",
    "    # Phase 2: Comprehensive data quality analysis\n",
    "    missing_analysis = comprehensive_data_quality_analysis(df)\n",
    "\n",
    "    # Mission completion summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 RESCUE MISSION EDA COMPLETE!\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"✅ Analyzed {len(df):,} passenger records\")\n",
    "    print(f\"✅ Generated comprehensive visualizations\")\n",
    "    print(f\"✅ Identified key rescue patterns\")\n",
    "    print(\"\\n🚨 Ready for model development phase!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Mission encountered error: {str(e)}\")\n",
    "    print(\"🔧 Check data source and dependencies\")"
   ],
   "id": "7e1e745ce6213e56",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 SPACESHIP TITANIC RESCUE MISSION INITIATED\n",
      "============================================================\n",
      "🚀 Starting Spaceship Titanic Rescue Mission Analysis...\n",
      "\n",
      "📊 PHASE 1: INTELLIGENCE GATHERING\n",
      "----------------------------------------\n",
      "🔍 Mission Log Analysis:\n",
      "   - Total passengers in manifest: 8,693\n",
      "   - Data integrity: 14 features recorded\n",
      "   - Missing data assessment needed...\n",
      "\n",
      "🔬 COMPREHENSIVE DATA QUALITY ANALYSIS\n",
      "---------------------------------------------\n",
      "Dataset Shape: (8693, 14)\n",
      "Memory Usage: 3.65 MB\n",
      "\n",
      "📋 MISSING DATA INTELLIGENCE REPORT:\n",
      "                    Column  Missing_Count  Missing_Percentage Data_Type\n",
      "CryoSleep        CryoSleep            217                2.50    object\n",
      "ShoppingMall  ShoppingMall            208                2.39   float64\n",
      "VIP                    VIP            203                2.34    object\n",
      "HomePlanet      HomePlanet            201                2.31    object\n",
      "Name                  Name            200                2.30    object\n",
      "Cabin                Cabin            199                2.29    object\n",
      "VRDeck              VRDeck            188                2.16   float64\n",
      "FoodCourt        FoodCourt            183                2.11   float64\n",
      "Spa                    Spa            183                2.11   float64\n",
      "Destination    Destination            182                2.09    object\n",
      "RoomService    RoomService            181                2.08   float64\n",
      "Age                    Age            179                2.06   float64\n",
      "\n",
      "⚖️ TARGET DISTRIBUTION ANALYSIS:\n",
      "Transported: 4,378 (50.4%)\n",
      "Not Transported: 4,315 (49.6%)\n",
      "\n",
      "📊 DATA TYPES SUMMARY:\n",
      "   object: 7 features\n",
      "   float64: 6 features\n",
      "   bool: 1 features\n",
      "\n",
      "============================================================\n",
      "🎉 RESCUE MISSION EDA COMPLETE!\n",
      "============================================================\n",
      "✅ Analyzed 8,693 passenger records\n",
      "✅ Generated comprehensive visualizations\n",
      "✅ Identified key rescue patterns\n",
      "\n",
      "🚨 Ready for model development phase!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:24.929660Z",
     "start_time": "2025-06-06T23:58:24.867458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# SPACESHIP TITANIC: FIXED FEATURE ENGINEERING PIPELINE\n",
    "# ================================================================\n",
    "# FIXES: Target leakage, overfitting, train/test inconsistencies\n",
    "# REMOVES: All target-derived features that cause 96% train vs 70% test gap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif, VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def basic_missing_value_imputation(df):\n",
    "    \"\"\"Basic imputation before feature engineering\"\"\"\n",
    "    print(\"🔧 Basic Missing Value Imputation...\")\n",
    "\n",
    "    # Age: Simple imputation first (will be improved later)\n",
    "    df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "\n",
    "    # Spending: Logical assumption - NaN means no spending\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    for col in spending_cols:\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "    # CryoSleep/VIP: Conservative assumption - NaN means False\n",
    "    df['CryoSleep'] = df['CryoSleep'].fillna(False)\n",
    "    df['VIP'] = df['VIP'].fillna(False)\n",
    "\n",
    "    # Categorical: Mode imputation with domain knowledge\n",
    "    df['HomePlanet'] = df['HomePlanet'].fillna(df['HomePlanet'].mode()[0])\n",
    "    df['Destination'] = df['Destination'].fillna(df['Destination'].mode()[0])\n",
    "\n",
    "    # Cabin: Create 'Unknown' category for missing values\n",
    "    df['Cabin'] = df['Cabin'].fillna('Unknown/0/U')\n",
    "\n",
    "    print(f\"   → Remaining missing values: {df.isnull().sum().sum()}\")\n",
    "    return df\n",
    "\n",
    "def advanced_missing_value_imputation(df):\n",
    "    \"\"\"Advanced hierarchical imputation after group features are created\"\"\"\n",
    "    print(\"🔧 Advanced Missing Value Imputation...\")\n",
    "\n",
    "    # Now we can do hierarchical imputation since PassengerGroup exists\n",
    "    if 'PassengerGroup' in df.columns:\n",
    "        # Age: Hierarchical imputation (Group → Planet → Global)\n",
    "        df['Age'] = df.groupby('PassengerGroup')['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "        df['Age'] = df.groupby('HomePlanet')['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "        df['Age'] = df['Age'].fillna(df['Age'].median())\n",
    "        print(\"   → Applied hierarchical age imputation\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def detect_and_handle_outliers(df):\n",
    "    \"\"\"Statistical outlier detection and treatment\"\"\"\n",
    "    print(\"📊 Outlier Detection & Treatment...\")\n",
    "\n",
    "    # Age outliers (beyond reasonable human lifespan)\n",
    "    age_outliers = (df['Age'] > 100).sum()\n",
    "    df['Age_Capped'] = df['Age'].clip(upper=100)\n",
    "\n",
    "    # Spending outliers using IQR method\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "\n",
    "    for col in spending_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "        outliers_count = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()\n",
    "        df[f'{col}_Capped'] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "        if outliers_count > 0:\n",
    "            print(f\"   → {col}: {outliers_count} outliers capped\")\n",
    "\n",
    "    # Create outlier flags (useful features)\n",
    "    df['HasAgeOutlier'] = (df['Age'] > 100).astype(int)\n",
    "    df['HasSpendingOutlier'] = ((df['RoomService'] > df['RoomService'].quantile(0.99)) |\n",
    "                                (df['FoodCourt'] > df['FoodCourt'].quantile(0.99)) |\n",
    "                                (df['ShoppingMall'] > df['ShoppingMall'].quantile(0.99)) |\n",
    "                                (df['Spa'] > df['Spa'].quantile(0.99)) |\n",
    "                                (df['VRDeck'] > df['VRDeck'].quantile(0.99))).astype(int)\n",
    "\n",
    "    print(f\"   → Age outliers: {age_outliers}\")\n",
    "    print(f\"   → Spending outliers flagged: {df['HasSpendingOutlier'].sum()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def engineer_passenger_groups(df):\n",
    "    \"\"\"Extract passenger group features - FIXED: No target leakage\"\"\"\n",
    "    print(\"🔍 Engineering Passenger Group Features...\")\n",
    "\n",
    "    # Parse PassengerId: format is \"group_member\" (e.g., \"0001_01\")\n",
    "    df['PassengerGroup'] = df['PassengerId'].str.extract('(\\d+)_').astype(int)\n",
    "    df['GroupMember'] = df['PassengerId'].str.extract('_(\\d+)').astype(int)\n",
    "\n",
    "    # Calculate group sizes\n",
    "    group_counts = df['PassengerGroup'].value_counts()\n",
    "    df['GroupSize'] = df['PassengerGroup'].map(group_counts)\n",
    "\n",
    "    # 🚨 REMOVED: GroupSurvivalRate - This was using target variable!\n",
    "    # Instead, use group characteristics that don't leak target info\n",
    "\n",
    "    # Solo travelers vs groups\n",
    "    df['IsSolo'] = (df['GroupSize'] == 1).astype(int)\n",
    "    df['IsLargeGroup'] = (df['GroupSize'] >= 5).astype(int)\n",
    "    df['IsMediumGroup'] = ((df['GroupSize'] >= 2) & (df['GroupSize'] <= 4)).astype(int)\n",
    "\n",
    "    # Group spending patterns - fix the syntax\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    group_total_spend = df.groupby('PassengerGroup')[spending_cols].sum().sum(axis=1)\n",
    "    df['GroupTotalSpend'] = df['PassengerGroup'].map(group_total_spend)\n",
    "\n",
    "    # Group age patterns (safe features)\n",
    "    group_age_stats = df.groupby('PassengerGroup')['Age'].agg(['mean', 'std', 'min', 'max'])\n",
    "    df['GroupAgeMean'] = df['PassengerGroup'].map(group_age_stats['mean'])\n",
    "    df['GroupAgeStd'] = df['PassengerGroup'].map(group_age_stats['std']).fillna(0)\n",
    "    df['GroupAgeRange'] = df['PassengerGroup'].map(group_age_stats['max'] - group_age_stats['min'])\n",
    "\n",
    "    print(f\"   → Group sizes: {df['GroupSize'].min()}-{df['GroupSize'].max()}\")\n",
    "    print(f\"   → Solo travelers: {df['IsSolo'].sum():,} ({df['IsSolo'].mean()*100:.1f}%)\")\n",
    "    print(\"   ✅ FIXED: Removed GroupSurvivalRate (target leakage)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def engineer_cabin_features(df):\n",
    "    \"\"\"Extract cabin location features - key predictor from EDA\"\"\"\n",
    "    print(\"🏢 Engineering Cabin Features...\")\n",
    "\n",
    "    # Parse cabin: format is \"deck/num/side\" (e.g., \"B/0/P\")\n",
    "    cabin_split = df['Cabin'].str.split('/', expand=True)\n",
    "    df['CabinDeck'] = cabin_split[0]\n",
    "    df['CabinNum'] = pd.to_numeric(cabin_split[1], errors='coerce')\n",
    "    df['CabinSide'] = cabin_split[2]\n",
    "\n",
    "    # EDA showed deck importance - encode numerically\n",
    "    deck_order = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'T': 8, 'Unknown': 0}\n",
    "    df['DeckLevel'] = df['CabinDeck'].map(deck_order)\n",
    "\n",
    "    # Side preference (Starboard showed better survival in EDA)\n",
    "    df['IsStarboard'] = (df['CabinSide'] == 'S').astype(int)\n",
    "    df['IsPort'] = (df['CabinSide'] == 'P').astype(int)\n",
    "    df['IsUnknownSide'] = (df['CabinSide'] == 'U').astype(int)\n",
    "\n",
    "    # Cabin number features\n",
    "    df['CabinNum'] = df['CabinNum'].fillna(0)\n",
    "    df['CabinNumQuartile'] = pd.qcut(df['CabinNum'].replace(0, np.nan), q=4, labels=[1,2,3,4]).astype(float)\n",
    "    df['CabinNumQuartile'] = df['CabinNumQuartile'].fillna(0)\n",
    "\n",
    "    # Cabin luxury indicators\n",
    "    df['IsLuxuryCabin'] = (df['CabinNumQuartile'] == 4).astype(int)\n",
    "    df['IsStandardCabin'] = (df['CabinNumQuartile'].isin([2, 3])).astype(int)\n",
    "\n",
    "    # Missing cabin indicates special case\n",
    "    df['HasCabin'] = (df['Cabin'] != 'Unknown/0/U').astype(int)\n",
    "\n",
    "    print(f\"   → Decks found: {sorted(df['CabinDeck'].unique())}\")\n",
    "    print(f\"   → Starboard preference: {df['IsStarboard'].mean()*100:.1f}%\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def engineer_spending_features(df):\n",
    "    \"\"\"Create spending features - major insight from EDA showing inverse relationship\"\"\"\n",
    "    print(\"💰 Engineering Spending Features...\")\n",
    "\n",
    "    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "    capped_spending_cols = [f'{col}_Capped' for col in spending_cols]\n",
    "\n",
    "    # Use capped versions for feature engineering\n",
    "    for orig, capped in zip(spending_cols, capped_spending_cols):\n",
    "        if capped in df.columns:\n",
    "            df[orig] = df[capped]\n",
    "\n",
    "    # Total spending (key finding: negative correlation with survival)\n",
    "    df['TotalSpend'] = df[spending_cols].sum(axis=1)\n",
    "\n",
    "    # Spending categories based on EDA patterns\n",
    "    df['LuxurySpend'] = df['Spa'] + df['VRDeck']\n",
    "    df['FoodSpend'] = df['RoomService'] + df['FoodCourt']\n",
    "    df['ShoppingSpend'] = df['ShoppingMall']\n",
    "\n",
    "    # Binary spending indicators\n",
    "    df['IsSpender'] = (df['TotalSpend'] > 0).astype(int)\n",
    "    df['IsHighSpender'] = (df['TotalSpend'] > df['TotalSpend'].quantile(0.75)).astype(int)\n",
    "    df['IsLowSpender'] = (df['TotalSpend'] <= df['TotalSpend'].quantile(0.25)).astype(int)\n",
    "    df['UsesLuxury'] = (df['LuxurySpend'] > 0).astype(int)\n",
    "\n",
    "    # Log transformations for skewed distributions\n",
    "    df['TotalSpend_Log'] = np.log1p(df['TotalSpend'])\n",
    "    df['LuxurySpend_Log'] = np.log1p(df['LuxurySpend'])\n",
    "    df['FoodSpend_Log'] = np.log1p(df['FoodSpend'])\n",
    "\n",
    "    # Square root transformations (alternative for skewed data)\n",
    "    df['TotalSpend_Sqrt'] = np.sqrt(df['TotalSpend'])\n",
    "\n",
    "    # Spending diversity (how many services used)\n",
    "    df['SpendDiversity'] = (df[spending_cols] > 0).sum(axis=1)\n",
    "\n",
    "    # Group spending patterns (safe features)\n",
    "    df['SpendPerGroupMember'] = df['TotalSpend'] / df['GroupSize']\n",
    "    df['SpendRatioInGroup'] = df['TotalSpend'] / (df['GroupTotalSpend'] + 1)\n",
    "\n",
    "    # Spending percentiles within group (safe ranking feature)\n",
    "    df['SpendPercentileInGroup'] = df.groupby('PassengerGroup')['TotalSpend'].rank(pct=True)\n",
    "\n",
    "    print(f\"   → Non-spenders: {(df['TotalSpend']==0).sum():,} ({(df['TotalSpend']==0).mean()*100:.1f}%)\")\n",
    "    print(f\"   → High spenders: {df['IsHighSpender'].sum():,} ({df['IsHighSpender'].mean()*100:.1f}%)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def engineer_demographic_features(df):\n",
    "    \"\"\"Create demographic features - FIXED: No target leakage\"\"\"\n",
    "    print(\"👤 Engineering Demographic Features...\")\n",
    "\n",
    "    # Use capped age\n",
    "    df['Age'] = df['Age_Capped']\n",
    "\n",
    "    # Age categories based on EDA survival patterns\n",
    "    df['IsChild'] = (df['Age'] < 13).astype(int)  # Children showed high survival\n",
    "    df['IsTeen'] = ((df['Age'] >= 13) & (df['Age'] < 18)).astype(int)\n",
    "    df['IsYoungAdult'] = ((df['Age'] >= 18) & (df['Age'] < 35)).astype(int)\n",
    "    df['IsMiddleAged'] = ((df['Age'] >= 35) & (df['Age'] < 60)).astype(int)\n",
    "    df['IsElderly'] = (df['Age'] >= 60).astype(int)\n",
    "\n",
    "    # Age transformations for non-linear relationships\n",
    "    df['Age_Squared'] = df['Age'] ** 2\n",
    "    df['Age_Log'] = np.log1p(df['Age'])\n",
    "    df['Age_Sqrt'] = np.sqrt(df['Age'])\n",
    "\n",
    "    # CryoSleep (major predictor from EDA - 82% survival rate)\n",
    "    df['CryoSleep'] = df['CryoSleep'].astype(int)\n",
    "\n",
    "    # VIP status (showed negative effect in EDA)\n",
    "    df['VIP'] = df['VIP'].astype(int)\n",
    "\n",
    "    # 🚨 REMOVED: All survival rate features that used target variable\n",
    "    # - PlanetSurvivalRate\n",
    "    # - DestSurvivalRate\n",
    "    # - PlanetDestSurvivalRate\n",
    "\n",
    "    # Instead, use frequency-based features (safe)\n",
    "    planet_counts = df['HomePlanet'].value_counts()\n",
    "    dest_counts = df['Destination'].value_counts()\n",
    "\n",
    "    df['PlanetFrequency'] = df['HomePlanet'].map(planet_counts)\n",
    "    df['DestFrequency'] = df['Destination'].map(dest_counts)\n",
    "\n",
    "    # Planet-destination combination frequency (safe)\n",
    "    planet_dest_counts = df.groupby(['HomePlanet', 'Destination']).size()\n",
    "    df['PlanetDestFrequency'] = df.set_index(['HomePlanet', 'Destination']).index.map(planet_dest_counts)\n",
    "\n",
    "    print(f\"   → Children: {df['IsChild'].sum():,} ({df['IsChild'].mean()*100:.1f}%)\")\n",
    "    print(f\"   → CryoSleep users: {df['CryoSleep'].sum():,} ({df['CryoSleep'].mean()*100:.1f}%)\")\n",
    "    print(f\"   → VIP passengers: {df['VIP'].sum():,} ({df['VIP'].mean()*100:.1f}%)\")\n",
    "    print(\"   ✅ FIXED: Removed survival rate features (target leakage)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def engineer_family_features(df):\n",
    "    \"\"\"Extract family relationships from names - FIXED: No target leakage\"\"\"\n",
    "    print(\"👨‍👩‍👧‍👦 Engineering Family Features...\")\n",
    "\n",
    "    # Extract first and last names\n",
    "    df['FirstName'] = df['Name'].str.split().str[0]\n",
    "    df['LastName'] = df['Name'].str.split().str[-1]\n",
    "\n",
    "    # Family size based on last name\n",
    "    family_counts = df['LastName'].value_counts()\n",
    "    df['FamilySize'] = df['LastName'].map(family_counts)\n",
    "\n",
    "    # 🚨 REMOVED: FamilySurvivalRate - This was using target variable!\n",
    "\n",
    "    # Family categories (safe features)\n",
    "    df['IsLargeFamily'] = (df['FamilySize'] >= 4).astype(int)\n",
    "    df['IsMediumFamily'] = (df['FamilySize'] == 2).astype(int)\n",
    "    df['IsSingleFamily'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "    # Family vs group relationship (safe features)\n",
    "    df['FamilyGroupRatio'] = df['FamilySize'] / df['GroupSize']\n",
    "    df['IsFamilyGroup'] = (df['FamilySize'] == df['GroupSize']).astype(int)\n",
    "\n",
    "    # Family name rarity (safe feature)\n",
    "    df['FamilyNameRarity'] = 1 / df['FamilySize']  # Rare names = higher values\n",
    "\n",
    "    print(f\"   → Family sizes: {df['FamilySize'].min()}-{df['FamilySize'].max()}\")\n",
    "    print(f\"   → Large families: {df['IsLargeFamily'].sum():,} ({df['IsLargeFamily'].mean()*100:.1f}%)\")\n",
    "    print(\"   ✅ FIXED: Removed FamilySurvivalRate (target leakage)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_safe_interaction_features(df):\n",
    "    \"\"\"Create interaction features - SAFE VERSION without target leakage\"\"\"\n",
    "    print(\"🔗 Creating Safe Interaction Features...\")\n",
    "\n",
    "    # Key interactions from EDA (safe versions)\n",
    "    df['Age_Spending_Interaction'] = df['Age'] * df['TotalSpend_Log']\n",
    "    df['Age_Group_Interaction'] = df['Age'] * df['GroupSize']\n",
    "    df['Deck_Side_Interaction'] = df['DeckLevel'] * df['IsStarboard']\n",
    "    df['Group_Spending_Interaction'] = df['GroupSize'] * df['TotalSpend_Log']\n",
    "\n",
    "    # CryoSleep interactions (major predictor)\n",
    "    df['Cryo_Age'] = df['CryoSleep'] * df['Age']\n",
    "    df['Cryo_Deck'] = df['CryoSleep'] * df['DeckLevel']\n",
    "    df['Cryo_VIP'] = df['CryoSleep'] * df['VIP']\n",
    "    df['Cryo_Spending'] = df['CryoSleep'] * df['TotalSpend_Log']\n",
    "    df['Cryo_Group'] = df['CryoSleep'] * df['GroupSize']\n",
    "\n",
    "    # VIP interactions\n",
    "    df['VIP_Spending'] = df['VIP'] * df['TotalSpend_Log']\n",
    "    df['VIP_Age'] = df['VIP'] * df['Age']\n",
    "    df['VIP_Deck'] = df['VIP'] * df['DeckLevel']\n",
    "\n",
    "    # Age-based interactions\n",
    "    df['Child_Cryo'] = df['IsChild'] * df['CryoSleep']\n",
    "    df['Child_VIP'] = df['IsChild'] * df['VIP']\n",
    "    df['Elderly_Cryo'] = df['IsElderly'] * df['CryoSleep']\n",
    "\n",
    "    # Reduced complexity interactions (prevent overfitting)\n",
    "    df['Age_Deck'] = df['Age'] * df['DeckLevel']\n",
    "    df['Spending_Deck'] = df['TotalSpend_Log'] * df['DeckLevel']\n",
    "\n",
    "    # Family-group interactions\n",
    "    df['Family_Group_Size'] = df['FamilySize'] * df['GroupSize']\n",
    "\n",
    "    print(f\"   → Created {16} safe interaction features\")\n",
    "    print(\"   ✅ REMOVED: Complex 3-way interactions to reduce overfitting\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def safe_categorical_encoding(df):\n",
    "    \"\"\"Encode categorical variables - SAFE VERSION without target leakage\"\"\"\n",
    "    print(\"🔤 Safe Categorical Encoding...\")\n",
    "\n",
    "    # 🚨 REMOVED: Target encoding - This was the major source of leakage!\n",
    "    # Target encoding uses the target variable to encode categories\n",
    "\n",
    "    # Frequency encoding for categorical features (safe)\n",
    "    freq_encode_features = ['HomePlanet', 'Destination', 'CabinDeck', 'FirstName', 'LastName']\n",
    "\n",
    "    for feature in freq_encode_features:\n",
    "        if feature in df.columns:\n",
    "            freq_map = df[feature].value_counts().to_dict()\n",
    "            df[f'{feature}_Frequency'] = df[feature].map(freq_map)\n",
    "\n",
    "    # One-hot encoding for low-cardinality features (safe)\n",
    "    onehot_features = ['HomePlanet', 'Destination', 'CabinDeck', 'CabinSide']\n",
    "\n",
    "    for feature in onehot_features:\n",
    "        if feature in df.columns:\n",
    "            dummies = pd.get_dummies(df[feature], prefix=feature, drop_first=True)\n",
    "            df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "    # Name length features (safe)\n",
    "    df['FirstNameLength'] = df['FirstName'].str.len()\n",
    "    df['LastNameLength'] = df['LastName'].str.len()\n",
    "    df['FullNameLength'] = df['FirstNameLength'] + df['LastNameLength']\n",
    "\n",
    "    # Name patterns (safe)\n",
    "    df['HasCommonFirstName'] = df['FirstName_Frequency'] > 10\n",
    "    df['HasRareLastName'] = df['LastName_Frequency'] <= 2\n",
    "\n",
    "    print(f\"   → Frequency encoded: {len(freq_encode_features)} features\")\n",
    "    print(f\"   → One-hot encoded: {len(onehot_features)} features\")\n",
    "    print(\"   ✅ REMOVED: Target encoding (major source of leakage)\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_final_feature_set(df):\n",
    "    \"\"\"Create final clean feature set for modeling\"\"\"\n",
    "    print(\"🎯 Creating Final Feature Set...\")\n",
    "\n",
    "    # Restore original PassengerId from backup\n",
    "    if '_PassengerId_Original' in df.columns:\n",
    "        df['PassengerId'] = df['_PassengerId_Original']\n",
    "        df = df.drop(columns=['_PassengerId_Original'])\n",
    "\n",
    "    # Remove identifier and text columns\n",
    "    drop_cols = [\n",
    "        'Name', 'FirstName', 'LastName', 'Cabin',\n",
    "        'HomePlanet', 'Destination', 'CabinDeck', 'CabinSide',\n",
    "        # Remove capped versions as we've already used them\n",
    "        'RoomService_Capped', 'FoodCourt_Capped', 'ShoppingMall_Capped',\n",
    "        'Spa_Capped', 'VRDeck_Capped', 'Age_Capped'\n",
    "    ]\n",
    "\n",
    "    final_df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "    # Convert any remaining object columns to numeric\n",
    "    for col in final_df.columns:\n",
    "        if final_df[col].dtype == 'object' and col != 'PassengerId':\n",
    "            le = LabelEncoder()\n",
    "            final_df[col] = le.fit_transform(final_df[col].astype(str))\n",
    "\n",
    "    # Final cleanup\n",
    "    final_df = final_df.fillna(0)\n",
    "\n",
    "    print(f\"   → Final dataset shape: {final_df.shape}\")\n",
    "    print(f\"   → Total features: {final_df.shape[1] - (1 if 'Transported' in final_df.columns else 0)}\")\n",
    "    print(f\"   → Memory usage: {final_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    return final_df\n",
    "\n",
    "def run_feature_engineering_pipeline(df):\n",
    "    \"\"\"FIXED Feature Engineering Pipeline - No Target Leakage\"\"\"\n",
    "    print(\"🚀 FIXED SPACESHIP TITANIC FEATURE ENGINEERING PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"🔧 FIXES:\")\n",
    "    print(\"   - Removed all target-derived features\")\n",
    "    print(\"   - Removed target encoding\")\n",
    "    print(\"   - Reduced complex interactions\")\n",
    "    print(\"   - Added regularization-friendly features\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Make an explicit copy and preserve PassengerId early\n",
    "    df = df.copy()\n",
    "    df['PassengerId'] = df['PassengerId'].astype(str)\n",
    "    df['_PassengerId_Original'] = df['PassengerId']\n",
    "\n",
    "    original_features = df.shape[1]\n",
    "\n",
    "    # Step 1: Basic preprocessing\n",
    "    df = basic_missing_value_imputation(df)\n",
    "    df = detect_and_handle_outliers(df)\n",
    "\n",
    "    # Step 2: Core feature engineering (FIXED)\n",
    "    df = engineer_passenger_groups(df)\n",
    "    df = advanced_missing_value_imputation(df)\n",
    "    df = engineer_cabin_features(df)\n",
    "    df = engineer_spending_features(df)\n",
    "    df = engineer_demographic_features(df)\n",
    "    df = engineer_family_features(df)\n",
    "\n",
    "    # Step 3: Safe advanced features\n",
    "    df = create_safe_interaction_features(df)\n",
    "    df = safe_categorical_encoding(df)\n",
    "\n",
    "    # Step 4: Final dataset\n",
    "    final_df = create_final_feature_set(df)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"🎉 FIXED FEATURE ENGINEERING COMPLETE!\")\n",
    "    print(f\"   📊 Original features: {original_features}\")\n",
    "    print(f\"   📊 Final features: {final_df.shape[1] - (1 if 'Transported' in final_df.columns else 0)}\")\n",
    "    print(f\"   📊 Feature expansion: {((final_df.shape[1] - 1) / original_features * 100):.1f}%\")\n",
    "    print(\"\\n🔧 KEY FIXES APPLIED:\")\n",
    "    print(\"   ✅ Removed GroupSurvivalRate (target leakage)\")\n",
    "    print(\"   ✅ Removed FamilySurvivalRate (target leakage)\")\n",
    "    print(\"   ✅ Removed PlanetSurvivalRate (target leakage)\")\n",
    "    print(\"   ✅ Removed DestSurvivalRate (target leakage)\")\n",
    "    print(\"   ✅ Removed Target Encoding (major leakage source)\")\n",
    "    print(\"   ✅ Reduced complex 3-way interactions\")\n",
    "    print(\"   ✅ Added frequency-based safe features\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Additional utility function for cross-validation target encoding (if needed)\n",
    "def safe_target_encoding_cv(df, categorical_col, target_col, n_folds=5, smoothing=10):\n",
    "    \"\"\"\n",
    "    Performs safe target encoding using cross-validation to prevent leakage.\n",
    "    Use this ONLY if you really need target encoding features.\n",
    "    \"\"\"\n",
    "    print(f\"🔒 Safe Target Encoding for {categorical_col} using {n_folds}-fold CV...\")\n",
    "\n",
    "    encoded_values = np.zeros(len(df))\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, val_idx in kf.split(df):\n",
    "        # Calculate target mean only on training fold\n",
    "        train_df = df.iloc[train_idx]\n",
    "        target_mean = train_df.groupby(categorical_col)[target_col].mean()\n",
    "        global_mean = train_df[target_col].mean()\n",
    "        category_counts = train_df.groupby(categorical_col).size()\n",
    "\n",
    "        # Apply smoothing to prevent overfitting\n",
    "        smoothed_means = (target_mean * category_counts + global_mean * smoothing) / (category_counts + smoothing)\n",
    "\n",
    "        # Encode validation fold\n",
    "        encoded_values[val_idx] = df.iloc[val_idx][categorical_col].map(smoothed_means).fillna(global_mean)\n",
    "\n",
    "    return encoded_values"
   ],
   "id": "79d43ec950dde0e8",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:26.225278Z",
     "start_time": "2025-06-06T23:58:25.410461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load the raw dataset\n",
    "df_train = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_train.csv\")\n",
    "\n",
    "# 2. Run the full feature engineering pipeline (ensure the function is defined)\n",
    "df_processed_train = run_feature_engineering_pipeline(df_train)\n",
    "\n",
    "# 3: Export the complete processed dataframe\n",
    "df_processed_train.to_csv('train_dataset_spaceship_titanic_processed.csv', index=False)\n",
    "print(f\"   ✅ Complete dataset exported: train_dataset_spaceship_titanic_processed.csv\")\n",
    "print(f\"   📊 Shape: {df_processed_train.shape}\")"
   ],
   "id": "88cb0c0f07eb9e40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 FIXED SPACESHIP TITANIC FEATURE ENGINEERING PIPELINE\n",
      "============================================================\n",
      "🔧 FIXES:\n",
      "   - Removed all target-derived features\n",
      "   - Removed target encoding\n",
      "   - Reduced complex interactions\n",
      "   - Added regularization-friendly features\n",
      "============================================================\n",
      "🔧 Basic Missing Value Imputation...\n",
      "   → Remaining missing values: 200\n",
      "📊 Outlier Detection & Treatment...\n",
      "   → RoomService: 1906 outliers capped\n",
      "   → FoodCourt: 1916 outliers capped\n",
      "   → ShoppingMall: 1879 outliers capped\n",
      "   → Spa: 1833 outliers capped\n",
      "   → VRDeck: 1849 outliers capped\n",
      "   → Age outliers: 0\n",
      "   → Spending outliers flagged: 408\n",
      "🔍 Engineering Passenger Group Features...\n",
      "   → Group sizes: 1-8\n",
      "   → Solo travelers: 4,805 (55.3%)\n",
      "   ✅ FIXED: Removed GroupSurvivalRate (target leakage)\n",
      "🔧 Advanced Missing Value Imputation...\n",
      "   → Applied hierarchical age imputation\n",
      "🏢 Engineering Cabin Features...\n",
      "   → Decks found: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Unknown']\n",
      "   → Starboard preference: 49.3%\n",
      "💰 Engineering Spending Features...\n",
      "   → Non-spenders: 3,653 (42.0%)\n",
      "   → High spenders: 2,169 (25.0%)\n",
      "👤 Engineering Demographic Features...\n",
      "   → Children: 806 (9.3%)\n",
      "   → CryoSleep users: 3,037 (34.9%)\n",
      "   → VIP passengers: 199 (2.3%)\n",
      "   ✅ FIXED: Removed survival rate features (target leakage)\n",
      "👨‍👩‍👧‍👦 Engineering Family Features...\n",
      "   → Family sizes: 1.0-18.0\n",
      "   → Large families: 6,147 (70.7%)\n",
      "   ✅ FIXED: Removed FamilySurvivalRate (target leakage)\n",
      "🔗 Creating Safe Interaction Features...\n",
      "   → Created 16 safe interaction features\n",
      "   ✅ REMOVED: Complex 3-way interactions to reduce overfitting\n",
      "🔤 Safe Categorical Encoding...\n",
      "   → Frequency encoded: 5 features\n",
      "   → One-hot encoded: 4 features\n",
      "   ✅ REMOVED: Target encoding (major source of leakage)\n",
      "🎯 Creating Final Feature Set...\n",
      "   → Final dataset shape: (8693, 107)\n",
      "   → Total features: 106\n",
      "   → Memory usage: 6.57 MB\n",
      "\n",
      "============================================================\n",
      "🎉 FIXED FEATURE ENGINEERING COMPLETE!\n",
      "   📊 Original features: 15\n",
      "   📊 Final features: 106\n",
      "   📊 Feature expansion: 706.7%\n",
      "\n",
      "🔧 KEY FIXES APPLIED:\n",
      "   ✅ Removed GroupSurvivalRate (target leakage)\n",
      "   ✅ Removed FamilySurvivalRate (target leakage)\n",
      "   ✅ Removed PlanetSurvivalRate (target leakage)\n",
      "   ✅ Removed DestSurvivalRate (target leakage)\n",
      "   ✅ Removed Target Encoding (major leakage source)\n",
      "   ✅ Reduced complex 3-way interactions\n",
      "   ✅ Added frequency-based safe features\n",
      "============================================================\n",
      "   ✅ Complete dataset exported: train_dataset_spaceship_titanic_processed.csv\n",
      "   📊 Shape: (8693, 107)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:26.840536Z",
     "start_time": "2025-06-06T23:58:26.239717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Load the raw dataset for Test set\n",
    "df_test = pd.read_csv(\"https://raw.githubusercontent.com/stepthom/869_course/refs/heads/main/data/spaceship_titanic_test.csv\")\n",
    "\n",
    "# 2. Run the full feature engineering pipeline (ensure the function is defined)\n",
    "df_processed_test = run_feature_engineering_pipeline(df_test)\n",
    "\n",
    "# 3: Export the complete processed dataframe\n",
    "df_processed_test.to_csv('test_dataset_spaceship_titanic_processed.csv', index=False)\n",
    "print(f\"   ✅ Complete dataset exported: test_dataset_spaceship_titanic_processed.csv\")\n",
    "print(f\"   📊 Shape: {df_processed_test.shape}\")"
   ],
   "id": "9bc3827e62302a3c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 FIXED SPACESHIP TITANIC FEATURE ENGINEERING PIPELINE\n",
      "============================================================\n",
      "🔧 FIXES:\n",
      "   - Removed all target-derived features\n",
      "   - Removed target encoding\n",
      "   - Reduced complex interactions\n",
      "   - Added regularization-friendly features\n",
      "============================================================\n",
      "🔧 Basic Missing Value Imputation...\n",
      "   → Remaining missing values: 94\n",
      "📊 Outlier Detection & Treatment...\n",
      "   → RoomService: 919 outliers capped\n",
      "   → FoodCourt: 931 outliers capped\n",
      "   → ShoppingMall: 912 outliers capped\n",
      "   → Spa: 921 outliers capped\n",
      "   → VRDeck: 927 outliers capped\n",
      "   → Age outliers: 0\n",
      "   → Spending outliers flagged: 193\n",
      "🔍 Engineering Passenger Group Features...\n",
      "   → Group sizes: 1-8\n",
      "   → Solo travelers: 2,340 (54.7%)\n",
      "   ✅ FIXED: Removed GroupSurvivalRate (target leakage)\n",
      "🔧 Advanced Missing Value Imputation...\n",
      "   → Applied hierarchical age imputation\n",
      "🏢 Engineering Cabin Features...\n",
      "   → Decks found: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Unknown']\n",
      "   → Starboard preference: 48.9%\n",
      "💰 Engineering Spending Features...\n",
      "   → Non-spenders: 1,804 (42.2%)\n",
      "   → High spenders: 1,067 (24.9%)\n",
      "👤 Engineering Demographic Features...\n",
      "   → Children: 351 (8.2%)\n",
      "   → CryoSleep users: 1,544 (36.1%)\n",
      "   → VIP passengers: 74 (1.7%)\n",
      "   ✅ FIXED: Removed survival rate features (target leakage)\n",
      "👨‍👩‍👧‍👦 Engineering Family Features...\n",
      "   → Family sizes: 1.0-14.0\n",
      "   → Large families: 1,812 (42.4%)\n",
      "   ✅ FIXED: Removed FamilySurvivalRate (target leakage)\n",
      "🔗 Creating Safe Interaction Features...\n",
      "   → Created 16 safe interaction features\n",
      "   ✅ REMOVED: Complex 3-way interactions to reduce overfitting\n",
      "🔤 Safe Categorical Encoding...\n",
      "   → Frequency encoded: 5 features\n",
      "   → One-hot encoded: 4 features\n",
      "   ✅ REMOVED: Target encoding (major source of leakage)\n",
      "🎯 Creating Final Feature Set...\n",
      "   → Final dataset shape: (4277, 106)\n",
      "   → Total features: 106\n",
      "   → Memory usage: 3.23 MB\n",
      "\n",
      "============================================================\n",
      "🎉 FIXED FEATURE ENGINEERING COMPLETE!\n",
      "   📊 Original features: 14\n",
      "   📊 Final features: 106\n",
      "   📊 Feature expansion: 750.0%\n",
      "\n",
      "🔧 KEY FIXES APPLIED:\n",
      "   ✅ Removed GroupSurvivalRate (target leakage)\n",
      "   ✅ Removed FamilySurvivalRate (target leakage)\n",
      "   ✅ Removed PlanetSurvivalRate (target leakage)\n",
      "   ✅ Removed DestSurvivalRate (target leakage)\n",
      "   ✅ Removed Target Encoding (major leakage source)\n",
      "   ✅ Reduced complex 3-way interactions\n",
      "   ✅ Added frequency-based safe features\n",
      "============================================================\n",
      "   ✅ Complete dataset exported: test_dataset_spaceship_titanic_processed.csv\n",
      "   📊 Shape: (4277, 106)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T23:58:28.487506Z",
     "start_time": "2025-06-06T23:58:28.476194Z"
    }
   },
   "cell_type": "code",
   "source": "df_processed_test.head(5)",
   "id": "d0149246e39981fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  PassengerId  CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall  \\\n",
       "0     0013_01          1  27.0    0          0.0        0.0           0.0   \n",
       "1     0018_01          0  19.0    0          0.0        9.0           0.0   \n",
       "2     0019_01          1  31.0    0          0.0        0.0           0.0   \n",
       "3     0021_01          0  38.0    0          0.0      165.0           0.0   \n",
       "4     0023_01          0  20.0    0         10.0        0.0          67.5   \n",
       "\n",
       "     Spa  VRDeck  HasAgeOutlier  ...  CabinDeck_G  CabinDeck_T  \\\n",
       "0    0.0     0.0              0  ...         True        False   \n",
       "1  107.5     0.0              0  ...        False        False   \n",
       "2    0.0     0.0              0  ...        False        False   \n",
       "3  107.5    77.5              0  ...        False        False   \n",
       "4    0.0     0.0              0  ...        False        False   \n",
       "\n",
       "   CabinDeck_Unknown  CabinSide_S  CabinSide_U  FirstNameLength  \\\n",
       "0              False         True        False              5.0   \n",
       "1              False         True        False              6.0   \n",
       "2              False         True        False              5.0   \n",
       "3              False         True        False              6.0   \n",
       "4              False         True        False              6.0   \n",
       "\n",
       "   LastNameLength  FullNameLength  HasCommonFirstName  HasRareLastName  \n",
       "0             9.0            14.0               False            False  \n",
       "1             7.0            13.0               False             True  \n",
       "2             9.0            14.0               False             True  \n",
       "3             9.0            15.0               False             True  \n",
       "4             8.0            14.0               False            False  \n",
       "\n",
       "[5 rows x 106 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>HasAgeOutlier</th>\n",
       "      <th>...</th>\n",
       "      <th>CabinDeck_G</th>\n",
       "      <th>CabinDeck_T</th>\n",
       "      <th>CabinDeck_Unknown</th>\n",
       "      <th>CabinSide_S</th>\n",
       "      <th>CabinSide_U</th>\n",
       "      <th>FirstNameLength</th>\n",
       "      <th>LastNameLength</th>\n",
       "      <th>FullNameLength</th>\n",
       "      <th>HasCommonFirstName</th>\n",
       "      <th>HasRareLastName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.5</td>\n",
       "      <td>77.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8468daf99ffeaea7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
