{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T04:21:27.336079Z",
     "start_time": "2025-06-04T04:21:27.327964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib"
   ],
   "id": "2658fec3d18f1655",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T04:21:27.990323Z",
     "start_time": "2025-06-04T04:21:27.986759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# üìä BLOCK: MODEL EVALUATION AND COMPETITION SUBMISSION\n",
    "print(\"üìä Starting Model Evaluation and Competition Submission\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: MODEL SELECTION AND LOADING\n",
    "# =============================================================================\n",
    "print(\"\\nüîç Available Models:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Available model files (based on your uploads)\n",
    "available_models = [\n",
    "    {'file': 'models/best_xgb_model.pkl', 'name': 'XGBoost (Grid Search)'},\n",
    "    {'file': 'models/best_xgb_random_model.pkl', 'name': 'XGBoost (Random Search)'},\n",
    "    {'file': 'models/best_xgb_tpe_model.pkl', 'name': 'XGBoost (TPE)'}\n",
    "]\n",
    "\n",
    "# Auto-select first available model (or manually change index)\n",
    "selected_model = available_models[0]  # Change to [1] or [2] for other models\n",
    "print(f\"‚úÖ Selected Model: {selected_model['name']}\")\n",
    "print(f\"üìÅ Model File: {selected_model['file']}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Starting Model Evaluation and Competition Submission\n",
      "============================================================\n",
      "\n",
      "üîç Available Models:\n",
      "------------------------------\n",
      "‚úÖ Selected Model: XGBoost (Grid Search)\n",
      "üìÅ Model File: models/best_xgb_model.pkl\n",
      "CPU times: user 56 Œºs, sys: 16 Œºs, total: 72 Œºs\n",
      "Wall time: 67.2 Œºs\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T06:19:30.826579Z",
     "start_time": "2025-06-04T06:19:30.772249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%time\n",
    "# =============================================================================\n",
    "# STEP 2: LOAD COMPETITION TEST DATA\n",
    "# =============================================================================\n",
    "print(f\"\\nüì• Loading Competition Test Data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Load competition test data\n",
    "X_comp = pd.read_csv('../data/processed/test_dataset_spaceship_titanic_processed.csv')\n",
    "print(f\"‚úÖ Competition test data loaded successfully\")\n",
    "print(f\"üìä Competition samples: {len(X_comp):,}\")\n",
    "\n",
    "# Save PassengerIds for submission\n",
    "passengerIDs = X_comp[\"PassengerId\"]\n",
    "print(f\"‚úÖ Passenger IDs extracted: {len(passengerIDs):,}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: PREPROCESS COMPETITION DATA\n",
    "# =============================================================================\n",
    "print(f\"\\nüîÑ Preprocessing Competition Data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Drop PassengerId column\n",
    "X_comp = X_comp.drop(['PassengerId'], axis=1, errors='ignore')"
   ],
   "id": "20e0ce4f5876ae12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Loading Competition Test Data\n",
      "----------------------------------------\n",
      "‚úÖ Competition test data loaded successfully\n",
      "üìä Competition samples: 4,277\n",
      "‚úÖ Passenger IDs extracted: 4,277\n",
      "\n",
      "üîÑ Preprocessing Competition Data\n",
      "----------------------------------------\n",
      "CPU times: user 20.6 ms, sys: 16.7 ms, total: 37.3 ms\n",
      "Wall time: 41.6 ms\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# STEP 3: LOAD MODEL AND GENERATE PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\nüîÑ Loading Model and Generating Predictions\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "# Load the model\n",
    "best_model = joblib.load(selected_model['file'])\n",
    "print(f\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "# Generate predictions on competition test set\n",
    "pred_comp = best_model.predict(X_comp)\n",
    "pred_proba_comp = best_model.predict_proba(X_comp)\n",
    "\n",
    "prediction_time = (datetime.now() - start_time).total_seconds()\n",
    "\n",
    "print(f\"‚úÖ Predictions generated successfully\")\n",
    "print(f\"üìä Competition samples: {len(X_comp):,}\")\n",
    "print(f\"‚è±Ô∏è  Prediction time: {prediction_time:.3f} seconds\")\n"
   ],
   "id": "d66482cf1cfc74df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# STEP 4: ANALYZE PREDICTIONS\n",
    "# =============================================================================\n",
    "print(f\"\\nüìä Prediction Analysis:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üéØ Model: {selected_model['name']}\")\n",
    "print(f\"üìä Total predictions: {len(pred_comp):,}\")\n",
    "print(f\"üìä Predicted class 0 (Not Transported): {(pred_comp == 0).sum():,} ({(pred_comp == 0).mean():.1%})\")\n",
    "print(f\"üìä Predicted class 1 (Transported): {(pred_comp == 1).sum():,} ({(pred_comp == 1).mean():.1%})\")\n",
    "print(f\"üìä Mean prediction probability: {pred_proba_comp[:, 1].mean():.3f}\")\n",
    "print(f\"üìä Prediction confidence (max prob): {pred_proba_comp.max(axis=1).mean():.3f}\")"
   ],
   "id": "45d235b462b0908d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# =============================================================================\n",
    "# STEP 5: CREATE SUBMISSION FILE\n",
    "# =============================================================================\n",
    "print(f\"\\nüíæ Creating Submission File\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Create submission dataframe\n",
    "my_submission = pd.DataFrame({\n",
    "    'PassengerId': passengerIDs,\n",
    "    'Transported': pred_comp.astype(bool)  # Convert to boolean as required by competition\n",
    "})\n",
    "\n",
    "# Display first 10 rows as sanity check\n",
    "print(f\"üìã Submission Preview:\")\n",
    "print(my_submission.head(10))\n",
    "\n",
    "# Save submission file\n",
    "submission_filename = f'submission_{selected_model[\"name\"].lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.csv'\n",
    "my_submission.to_csv(submission_filename, index=False)\n",
    "print(f\"‚úÖ Submission saved to: {submission_filename}\")"
   ],
   "id": "f11c45844cd7f520",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# STEP 6: SAVE DETAILED PREDICTIONS (OPTIONAL)\n",
    "# =============================================================================\n",
    "print(f\"\\nüíæ Saving Detailed Predictions\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# Create detailed predictions dataframe\n",
    "detailed_predictions = pd.DataFrame({\n",
    "    'PassengerId': passengerIDs,\n",
    "    'Predicted_Label': pred_comp,\n",
    "    'Prediction_Probability_Not_Transported': pred_proba_comp[:, 0],\n",
    "    'Prediction_Probability_Transported': pred_proba_comp[:, 1],\n",
    "    'Prediction_Confidence': pred_proba_comp.max(axis=1)\n",
    "})\n",
    "\n",
    "detailed_filename = f'detailed_predictions_{selected_model[\"name\"].lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.csv'\n",
    "detailed_predictions.to_csv(detailed_filename, index=False)\n",
    "print(f\"‚úÖ Detailed predictions saved to: {detailed_filename}\")"
   ],
   "id": "421507dfe27ffdf7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# STEP 7: NOTE ABOUT TEST SET\n",
    "# =============================================================================\n",
    "print(f\"\\nüìù Important Note About Test Set\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚ÑπÔ∏è  The competition test set has NO labels (no 'Transported' column)\")\n",
    "print(\"‚ÑπÔ∏è  This is the unlabeled data you need to predict for submission\")\n",
    "print(\"‚ÑπÔ∏è  True performance will only be known after Kaggle submission\")\n",
    "print(\"‚ÑπÔ∏è  Use cross-validation scores from training as performance estimates\")"
   ],
   "id": "b9435b5914a25d1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# =============================================================================\n",
    "# STEP 8: SUMMARY\n",
    "# =============================================================================\n",
    "end_time = datetime.now()\n",
    "total_runtime = (end_time - start_time).total_seconds()\n",
    "\n",
    "print(f\"\\nüìà EVALUATION SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"‚úÖ Model: {selected_model['name']}\")\n",
    "print(f\"üìÅ Model File: {selected_model['file']}\")\n",
    "print(f\"üîÆ Competition Samples: {len(X_comp):,}\")\n",
    "print(f\"‚è±Ô∏è  Total Runtime: {total_runtime:.2f} seconds\")\n",
    "\n",
    "print(f\"\\nüìä Files Generated:\")\n",
    "print(f\"   ‚Ä¢ {submission_filename} (Main submission file)\")\n",
    "print(f\"   ‚Ä¢ {detailed_filename} (Detailed predictions)\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps:\")\n",
    "print(f\"   1. Upload '{submission_filename}' to Kaggle competition\")\n",
    "print(f\"   2. Check leaderboard performance\")\n",
    "print(f\"   3. Compare with cross-validation scores from training\")\n",
    "print(f\"   4. Consider ensemble methods if performance differs significantly\")\n",
    "\n",
    "print(f\"\\n‚úÖ Model evaluation and submission preparation completed successfully!\")\n",
    "print(\"=\" * 60)"
   ],
   "id": "99bb44bcb6b0f5e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
