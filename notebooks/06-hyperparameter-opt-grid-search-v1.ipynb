{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "e1fb3e75cfaf4eac98c30f1b650f9f61": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dc4b7c5f9374c91a345eb9a8cff52f1",
       "IPY_MODEL_675f971bb3474886b7e2937e9abbe924",
       "IPY_MODEL_042cc973049b4bd38dd76ed12673c5ed"
      ],
      "layout": "IPY_MODEL_990c81edd0cd45f2b51a64c6939eb5b3"
     }
    },
    "0dc4b7c5f9374c91a345eb9a8cff52f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1493091bac6f4b3e939ca5fa8f8c75de",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c857c51c01234807b969b64c5a82cbff",
      "value": "Best‚Äátrial:‚Äá65.‚ÄáBest‚Äávalue:‚Äá0.964568:‚Äá100%"
     }
    },
    "675f971bb3474886b7e2937e9abbe924": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52b470330cee4f0ca7841bb18d0d40ab",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67f26fc4f3de4c28b1fbe26f2f100f72",
      "value": 100
     }
    },
    "042cc973049b4bd38dd76ed12673c5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eca2bff412c64b2386a0a795c398cb6f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_32977e762de24e1cadad3b95f787753f",
      "value": "‚Äá100/100‚Äá[02:04&lt;00:00,‚Äá‚Äá1.17s/it]"
     }
    },
    "990c81edd0cd45f2b51a64c6939eb5b3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1493091bac6f4b3e939ca5fa8f8c75de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c857c51c01234807b969b64c5a82cbff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "52b470330cee4f0ca7841bb18d0d40ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67f26fc4f3de4c28b1fbe26f2f100f72": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eca2bff412c64b2386a0a795c398cb6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32977e762de24e1cadad3b95f787753f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z8miWz8zKnb7",
    "outputId": "888bf915-9d2f-4c56-e5e0-bca6ea5fc753"
   },
   "source": [
    "%cd /content\n",
    "!git clone https://github.com/deenuy/869-spaceship-titanic.git\n",
    "# !git pull origin main"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -r /content/869-spaceship-titanic/requirements.txt"
   ],
   "metadata": {
    "id": "nJgwiMENc30Y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "76e34e99-a0fc-425b-a585-887a0f7653a8"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preliminaries: Inspect and Set up environment\n",
    "\n",
    "No action is required on your part in this section. These cells print out helpful information about the environment, just in case."
   ],
   "metadata": {
    "id": "RJOzHNdg8XHo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# üß∞ General-purpose libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "\n",
    "\n",
    "# üß™ Scikit-learn preprocessing & pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# üîç Scikit-learn model selection\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold\n",
    ")\n",
    "\n",
    "# üß† Scikit-learn classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# üöÄ Gradient boosting frameworks\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# üìä Evaluation\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# üß™ Sample dataset (for testing/demo)\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n"
   ],
   "metadata": {
    "id": "-eeFtKdG8WRK",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:10:19.724858Z",
     "start_time": "2025-06-06T20:10:19.233966Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# LOAD TRAINING DATA WITH SELECTED FEATURES\n",
    "# ================================================================\n",
    "\n",
    "print(\"üì• LOADING TRAINING DATA WITH SELECTED FEATURES\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Load complete processed training dataset\n",
    "df_processed = pd.read_csv('../data/processed/train_features_engineered.csv')\n",
    "print(f\"   ‚úÖ Training dataset loaded: {df_processed.shape}\")\n",
    "\n",
    "# Load selected features from feature selection phase\n",
    "best_features = pd.read_csv('../data/processed/best_features_selected.csv')['best_features'].tolist()\n",
    "print(f\"   ‚úÖ Selected features loaded: {len(best_features)} features\")\n",
    "\n",
    "# Filter training data using selected features only\n",
    "X_train = df_processed[best_features]\n",
    "y_train = df_processed['Transported']\n",
    "\n",
    "print(f\"\\nüìä FILTERED TRAINING DATA SUMMARY:\")\n",
    "print(f\"   üìä Original features: {df_processed.shape[1] - 2}\")  # Exclude PassengerId and Transported\n",
    "print(f\"   üìä Selected features: {X_train.shape[1]}\")\n",
    "print(f\"   üìä Feature reduction: {((df_processed.shape[1] - 2 - X_train.shape[1]) / (df_processed.shape[1] - 2) * 100):.1f}%\")\n",
    "print(f\"   üìä Training samples: {X_train.shape[0]}\")\n",
    "print(f\"   üìä Target distribution: {y_train.sum()}/{len(y_train)} transported\")\n",
    "\n",
    "print(f\"\\nüéØ SELECTED FEATURES FOR OPTIMIZATION:\")\n",
    "for i, feature in enumerate(best_features, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training data ready for hyperparameter optimization!\")"
   ],
   "metadata": {
    "id": "UGwYX_gccUTq",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:10:19.816266Z",
     "start_time": "2025-06-06T20:10:19.800791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• LOADING TRAINING DATA WITH SELECTED FEATURES\n",
      "=======================================================\n",
      "   ‚úÖ Training dataset loaded: (8693, 19)\n",
      "   ‚úÖ Selected features loaded: 6 features\n",
      "\n",
      "üìä FILTERED TRAINING DATA SUMMARY:\n",
      "   üìä Original features: 17\n",
      "   üìä Selected features: 6\n",
      "   üìä Feature reduction: 64.7%\n",
      "   üìä Training samples: 8693\n",
      "   üìä Target distribution: 4378/8693 transported\n",
      "\n",
      "üéØ SELECTED FEATURES FOR OPTIMIZATION:\n",
      "    1. HomePlanet\n",
      "    2. CryoSleep\n",
      "    3. RoomService\n",
      "    4. TotalSpend\n",
      "    5. LuxurySpend\n",
      "    6. Cabin_HomePlanet\n",
      "\n",
      "‚úÖ Training data ready for hyperparameter optimization!\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1: Hyperparameter Tuning of XGBoost for Accuracy Optimization using Grid Search\n",
    "This step fine-tunes the XGBoost model using GridSearchCV with 5-fold cross-validation, targeting improved accuracy aligned with leaderboard evaluation. The objective is to systematically identify optimal configurations for deployment while maintaining generalizability and avoiding overfitting through complete hyperparameter exploration within defined ranges.\n",
    "\n",
    "Hyperparameter Tuning of XGBoost using Grid Search, includes feature engineering integrated into a pipeline using ColumnTransformer. This version includes:\n",
    "\n",
    "* Modular pipeline with XGBoost\n",
    "* Grid search over refined hyperparameter ranges based on domain expertise\n",
    "* Accuracy as the scoring metric\n",
    "* Systematic parameter space exploration through complete enumeration within grid boundaries\n",
    "* Deterministic and reproducible results with guaranteed optimal discovery\n",
    "* Computational cost scaling with comprehensive coverage of all parameter combinations"
   ],
   "metadata": {
    "id": "_O6RB-aKgaNs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "\n",
    "# Pipeline with preprocessing + model\n",
    "full_pipeline = Pipeline([\n",
    "    # ('preprocessing', preprocessor),\n",
    "    ('clf', XGBClassifier(eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space for XGBoost (refined around best random search results)\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [150, 200, 250],              # 3 values (was 4)\n",
    "    'clf__max_depth': [5, 6, 7],                       # 3 values (was 3) ‚úì\n",
    "    'clf__learning_rate': [0.03, 0.05, 0.07],          # 3 values (was 4)\n",
    "    'clf__subsample': [0.9, 1.0],                      # 2 values (was 3)\n",
    "    'clf__colsample_bytree': [0.9, 1.0],               # 2 values (was 3)\n",
    "    'clf__reg_alpha': [0.01, 0.02],                    # 2 values (was 3)\n",
    "    'clf__reg_lambda': [0.8, 1.2],                     # 2 values (was 3)\n",
    "    'clf__min_child_weight': [1, 3]                    # 2 values (was 3)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization using GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',        # Main leaderboard metric\n",
    "    cv=5,                      # 5-fold cross-validation\n",
    "    n_jobs=-1,                 # Parallel execution\n",
    "    verbose=1,                 # Print progress\n",
    "    return_train_score=True    # Track training performance\n",
    ")\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "start_time = datetime.now()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "# Print best result and CV performance\n",
    "print(\"üéØ Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\n‚úÖ Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Extract all grid search results for tracking\n",
    "cv_results = grid_search.cv_results_\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(cv_results['params'])):\n",
    "    # Extract hyperparameters\n",
    "    params = cv_results['params'][i]\n",
    "    clean_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
    "\n",
    "    # Get CV scores for each fold\n",
    "    cv_scores = []\n",
    "    for fold in range(5):\n",
    "        cv_scores.append(cv_results[f'split{fold}_test_score'][i])\n",
    "\n",
    "    # Create result record\n",
    "    result = {\n",
    "        'Model': 'XGBoost',\n",
    "        'Hyperparameters': str(clean_params),\n",
    "        'CV_Accuracy_Mean': cv_results['mean_test_score'][i],\n",
    "        'CV_Accuracy_Std': cv_results['std_test_score'][i],\n",
    "        'CV_Accuracy_Min': min(cv_scores),\n",
    "        'CV_Accuracy_Max': max(cv_scores),\n",
    "        'Rank': cv_results['rank_test_score'][i],\n",
    "        'Is_Best': i == grid_search.best_index_,\n",
    "        'Runtime_Seconds': (end_time - start_time).total_seconds()\n",
    "    }\n",
    "\n",
    "    # Add individual hyperparameters as separate columns\n",
    "    for param_name, param_value in clean_params.items():\n",
    "        result[f'{param_name}'] = param_value\n",
    "\n",
    "    results_list.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display top 10 configurations\n",
    "print(\"\\nüìä TOP 10 CONFIGURATIONS:\")\n",
    "top_configs = results_df.nlargest(10, 'CV_Accuracy_Mean')[\n",
    "    ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'Hyperparameters', 'Rank']\n",
    "]\n",
    "print(top_configs.to_string(index=False))\n",
    "\n",
    "# Show accuracy range\n",
    "print(f\"\\nüìà PERFORMANCE SUMMARY:\")\n",
    "print(f\"Total experiments: {len(results_df)}\")\n",
    "print(f\"Best CV Accuracy: {results_df['CV_Accuracy_Mean'].max():.4f}\")\n",
    "print(f\"Worst CV Accuracy: {results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
    "print(f\"Accuracy Range: {results_df['CV_Accuracy_Mean'].max() - results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
    "print(f\"Total Runtime: {(end_time - start_time).total_seconds():.2f} seconds\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('results/xgboost_grid_search_results.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to: results/xgboost_grid_search_results.csv\")\n",
    "\n",
    "# Extract best model for reuse or export\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, '../models/best_xgb_grid_model.pkl')\n",
    "print(\"‚úÖ Best model saved to: models/best_xgb_grid_model.pkl\")\n",
    "\n",
    "# Display detailed results table\n",
    "print(f\"\\nüìã DETAILED RESULTS TABLE:\")\n",
    "display_cols = ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'n_estimators', 'max_depth', 'learning_rate', 'subsample', 'colsample_bytree', 'Rank']\n",
    "# results_df[display_cols].round(2).head(15)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1ChyiPCgbJR",
    "outputId": "45a3e5d1-7d3b-4d41-fe99-3b3d9cf9ccc2",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:14:57.661422Z",
     "start_time": "2025-06-06T20:13:57.695907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "üéØ Best Hyperparameters:\n",
      "{'clf__colsample_bytree': 0.9, 'clf__learning_rate': 0.07, 'clf__max_depth': 7, 'clf__min_child_weight': 1, 'clf__n_estimators': 150, 'clf__reg_alpha': 0.01, 'clf__reg_lambda': 0.8, 'clf__subsample': 1.0}\n",
      "\n",
      "‚úÖ Best CV Accuracy: 0.7997\n",
      "\n",
      "üìä TOP 10 CONFIGURATIONS:\n",
      "  Model  CV_Accuracy_Mean  CV_Accuracy_Std                                                                                                                                                      Hyperparameters  Rank\n",
      "XGBoost          0.799726         0.010206 {'colsample_bytree': 0.9, 'learning_rate': 0.07, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.01, 'reg_lambda': 0.8, 'subsample': 1.0}     1\n",
      "XGBoost          0.799381         0.008199 {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 250, 'reg_alpha': 0.01, 'reg_lambda': 0.8, 'subsample': 0.9}     2\n",
      "XGBoost          0.799152         0.012899 {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 250, 'reg_alpha': 0.01, 'reg_lambda': 1.2, 'subsample': 1.0}     3\n",
      "XGBoost          0.799151         0.008172 {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 250, 'reg_alpha': 0.01, 'reg_lambda': 1.2, 'subsample': 0.9}     4\n",
      "XGBoost          0.799151         0.007930 {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0.01, 'reg_lambda': 0.8, 'subsample': 0.9}     5\n",
      "XGBoost          0.799151         0.007616 {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 250, 'reg_alpha': 0.02, 'reg_lambda': 1.2, 'subsample': 0.9}     6\n",
      "XGBoost          0.799036         0.010274 {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.02, 'reg_lambda': 1.2, 'subsample': 0.9}     7\n",
      "XGBoost          0.798921         0.008261 {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 250, 'reg_alpha': 0.02, 'reg_lambda': 1.2, 'subsample': 1.0}     8\n",
      "XGBoost          0.798921         0.008803 {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'reg_alpha': 0.01, 'reg_lambda': 1.2, 'subsample': 0.9}     8\n",
      "XGBoost          0.798921         0.008882 {'colsample_bytree': 0.9, 'learning_rate': 0.03, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 150, 'reg_alpha': 0.01, 'reg_lambda': 0.8, 'subsample': 0.9}    10\n",
      "\n",
      "üìà PERFORMANCE SUMMARY:\n",
      "Total experiments: 864\n",
      "Best CV Accuracy: 0.7997\n",
      "Worst CV Accuracy: 0.7919\n",
      "Accuracy Range: 0.0078\n",
      "Total Runtime: 59.90 seconds\n",
      "\n",
      "üíæ Results saved to: results/xgboost_grid_search_results.csv\n",
      "‚úÖ Best model saved to: models/best_xgb_grid_model.pkl\n",
      "\n",
      "üìã DETAILED RESULTS TABLE:\n",
      "CPU times: user 4.38 s, sys: 1.5 s, total: 5.88 s\n",
      "Wall time: 59.9 s\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2: Hyperparameter Tuning of CatBoost for Accuracy Optimization using Grid Search\n",
    "This step fine-tunes the CatBoost model using GridSearchCV with 5-fold cross-validation, targeting improved accuracy aligned with leaderboard evaluation. The objective is to systematically identify optimal configurations for deployment while maintaining generalizability and avoiding overfitting through complete hyperparameter exploration within defined ranges.\n",
    "\n",
    "Hyperparameter Tuning of CatBoost using Grid Search, leveraging CatBoost's native categorical feature handling. This version includes:\n",
    "\n",
    "* Native categorical feature processing without preprocessing\n",
    "* Gradient boosting with advanced regularization techniques\n",
    "* Grid search over refined CatBoost-specific hyperparameter ranges based on literature review\n",
    "* Accuracy as the scoring metric\n",
    "* Systematic parameter space exploration through complete enumeration within grid boundaries\n",
    "* Advanced overfitting prevention through bagging temperature and random strength\n",
    "* Deterministic and reproducible results with guaranteed optimal discovery\n",
    "* Computational cost scaling with comprehensive coverage of all parameter combinations"
   ],
   "metadata": {
    "id": "uzJd1h9khaRA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "\n",
    "# Pipeline with preprocessing + model\n",
    "full_pipeline = Pipeline([\n",
    "    # ('preprocessing', preprocessor),\n",
    "    ('clf', CatBoostClassifier(verbose=0, random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space for CatBoost (fine-tuned grid based on random search findings)\n",
    "param_grid = {\n",
    "    'clf__iterations': [600, 800],                     # 2 values (was 4)\n",
    "    'clf__depth': [3, 4, 5],                          # 3 values (was 3) ‚úì\n",
    "    'clf__learning_rate': [0.025, 0.035],             # 2 values (was 4)\n",
    "    'clf__l2_leaf_reg': [7, 11],                      # 2 values (was 3)\n",
    "    'clf__border_count': [128, 254],                  # 2 values (was 3)\n",
    "    'clf__bagging_temperature': [0.3, 0.7],          # 2 values (was 3)\n",
    "    'clf__random_strength': [1.5, 2.5],              # 2 values (was 3)\n",
    "    'clf__od_type': ['Iter']                          # 1 value (was 2)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization using GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',        # Main leaderboard metric\n",
    "    cv=5,                      # 5-fold cross-validation\n",
    "    n_jobs=-1,                 # Parallel execution\n",
    "    verbose=1,                 # Print progress\n",
    "    return_train_score=True    # Track training performance\n",
    ")\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "start_time = datetime.now()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "# Print best result and CV performance\n",
    "print(\"üéØ Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\n‚úÖ Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Extract all grid search results for tracking\n",
    "cv_results = grid_search.cv_results_\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(cv_results['params'])):\n",
    "    # Extract hyperparameters\n",
    "    params = cv_results['params'][i]\n",
    "    clean_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
    "\n",
    "    # Get CV scores for each fold\n",
    "    cv_scores = []\n",
    "    for fold in range(5):\n",
    "        cv_scores.append(cv_results[f'split{fold}_test_score'][i])\n",
    "\n",
    "    # Create result record\n",
    "    result = {\n",
    "        'Model': 'CatBoost',\n",
    "        'Hyperparameters': str(clean_params),\n",
    "        'CV_Accuracy_Mean': cv_results['mean_test_score'][i],\n",
    "        'CV_Accuracy_Std': cv_results['std_test_score'][i],\n",
    "        'CV_Accuracy_Min': min(cv_scores),\n",
    "        'CV_Accuracy_Max': max(cv_scores),\n",
    "        'Rank': cv_results['rank_test_score'][i],\n",
    "        'Is_Best': i == grid_search.best_index_,\n",
    "        'Runtime_Seconds': (end_time - start_time).total_seconds()\n",
    "    }\n",
    "\n",
    "    # Add individual hyperparameters as separate columns\n",
    "    for param_name, param_value in clean_params.items():\n",
    "        result[f'{param_name}'] = param_value\n",
    "\n",
    "    results_list.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display top 10 configurations\n",
    "print(\"\\nüìä TOP 10 CONFIGURATIONS:\")\n",
    "top_configs = results_df.nlargest(10, 'CV_Accuracy_Mean')[\n",
    "    ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'Hyperparameters', 'Rank']\n",
    "]\n",
    "print(top_configs.to_string(index=False))\n",
    "\n",
    "# Show accuracy range\n",
    "print(f\"\\nüìà PERFORMANCE SUMMARY:\")\n",
    "print(f\"Total experiments: {len(results_df)}\")\n",
    "print(f\"Best CV Accuracy: {results_df['CV_Accuracy_Mean'].max():.4f}\")\n",
    "print(f\"Worst CV Accuracy: {results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
    "print(f\"Accuracy Range: {results_df['CV_Accuracy_Mean'].max() - results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
    "print(f\"Total Runtime: {(end_time - start_time).total_seconds():.2f} seconds\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('results/catboost_grid_search_results.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to: results/catboost_grid_search_results.csv\")\n",
    "\n",
    "# Extract best model for reuse or export\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, 'best_catboost_grid_model.pkl')\n",
    "print(\"‚úÖ Best model saved to: best_catboost_grid_model.pkl\")\n",
    "\n",
    "# Display detailed results table\n",
    "print(f\"\\nüìã DETAILED RESULTS TABLE:\")\n",
    "display_cols = ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'iterations', 'depth', 'learning_rate', 'l2_leaf_reg', 'bagging_temperature', 'Rank']\n",
    "# results_df[display_cols].round(2).head(15)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-li9uOMFhajo",
    "outputId": "104041d8-aece-49ad-9002-ba3767567dbf",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:18:27.265276Z",
     "start_time": "2025-06-06T20:14:57.693374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "üéØ Best Hyperparameters:\n",
      "{'clf__bagging_temperature': 0.3, 'clf__border_count': 128, 'clf__depth': 4, 'clf__iterations': 800, 'clf__l2_leaf_reg': 7, 'clf__learning_rate': 0.035, 'clf__od_type': 'Iter', 'clf__random_strength': 2.5}\n",
      "\n",
      "‚úÖ Best CV Accuracy: 0.8016\n",
      "\n",
      "üìä TOP 10 CONFIGURATIONS:\n",
      "   Model  CV_Accuracy_Mean  CV_Accuracy_Std                                                                                                                                                        Hyperparameters  Rank\n",
      "CatBoost          0.801569         0.016349  {'bagging_temperature': 0.3, 'border_count': 128, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 7, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     1\n",
      "CatBoost          0.801569         0.016349  {'bagging_temperature': 0.7, 'border_count': 128, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 7, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     1\n",
      "CatBoost          0.801568         0.013651 {'bagging_temperature': 0.3, 'border_count': 254, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 11, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     3\n",
      "CatBoost          0.801568         0.013651 {'bagging_temperature': 0.7, 'border_count': 254, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 11, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     3\n",
      "CatBoost          0.801453         0.014191  {'bagging_temperature': 0.3, 'border_count': 254, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 7, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     5\n",
      "CatBoost          0.801453         0.014191  {'bagging_temperature': 0.7, 'border_count': 254, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 7, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     5\n",
      "CatBoost          0.801338         0.013101 {'bagging_temperature': 0.3, 'border_count': 128, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 11, 'learning_rate': 0.025, 'od_type': 'Iter', 'random_strength': 1.5}     7\n",
      "CatBoost          0.801338         0.013101 {'bagging_temperature': 0.7, 'border_count': 128, 'depth': 4, 'iterations': 800, 'l2_leaf_reg': 11, 'learning_rate': 0.025, 'od_type': 'Iter', 'random_strength': 1.5}     7\n",
      "CatBoost          0.800762         0.012323 {'bagging_temperature': 0.3, 'border_count': 128, 'depth': 4, 'iterations': 600, 'l2_leaf_reg': 11, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     9\n",
      "CatBoost          0.800762         0.012323 {'bagging_temperature': 0.7, 'border_count': 128, 'depth': 4, 'iterations': 600, 'l2_leaf_reg': 11, 'learning_rate': 0.035, 'od_type': 'Iter', 'random_strength': 2.5}     9\n",
      "\n",
      "üìà PERFORMANCE SUMMARY:\n",
      "Total experiments: 192\n",
      "Best CV Accuracy: 0.8016\n",
      "Worst CV Accuracy: 0.7954\n",
      "Accuracy Range: 0.0062\n",
      "Total Runtime: 209.53 seconds\n",
      "\n",
      "üíæ Results saved to: results/catboost_grid_search_results.csv\n",
      "‚úÖ Best model saved to: best_catboost_grid_model.pkl\n",
      "\n",
      "üìã DETAILED RESULTS TABLE:\n",
      "CPU times: user 4 s, sys: 2.24 s, total: 6.24 s\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 3: Hyperparameter Tuning of Gradient Boosting for Accuracy Optimization using Grid Search\n",
    "This step fine-tunes the Gradient Boosting model using GridSearchCV with 5-fold cross-validation, targeting improved accuracy aligned with leaderboard evaluation. The objective is to systematically identify optimal configurations for deployment while maintaining generalizability and avoiding overfitting through complete hyperparameter exploration within defined ranges.\n",
    "\n",
    "Hyperparameter Tuning of Gradient Boosting using Grid Search, utilizing scikit-learn's robust implementation. This version includes:\n",
    "\n",
    "* Sequential boosting with sample and feature subsampling\n",
    "* Tree-based weak learners with configurable depth and split criteria\n",
    "* Grid search over refined gradient boosting hyperparameter ranges based on domain expertise\n",
    "* Accuracy as the scoring metric\n",
    "* Systematic parameter space exploration through complete enumeration within grid boundaries\n",
    "* Overfitting control through subsample ratios and leaf constraints\n",
    "* Deterministic and reproducible results with guaranteed optimal discovery\n",
    "* Computational cost scaling with comprehensive coverage of all parameter combinations"
   ],
   "metadata": {
    "id": "rbqQDNQqhRT5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "%%time\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import joblib\n",
    "\n",
    "# Pipeline with preprocessing + model\n",
    "full_pipeline = Pipeline([\n",
    "    # ('preprocessing', preprocessor),\n",
    "    ('clf', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter search space for Gradient Boosting (fine-tuned grid based on random search findings)\n",
    "param_grid =  {\n",
    "    'clf__n_estimators': [250, 350],                  # 2 values (was 3)\n",
    "    'clf__max_depth': [3, 4],                         # 2 values (was 2) ‚úì\n",
    "    'clf__learning_rate': [0.06, 0.08],               # 2 values (was 3)\n",
    "    'clf__subsample': [0.85, 0.95],                   # 2 values (was 3)\n",
    "    'clf__min_samples_split': [12, 18],               # 2 values (was 3)\n",
    "    'clf__min_samples_leaf': [4, 8],                  # 2 values (was 3)\n",
    "    'clf__max_features': ['log2', 0.8],               # 2 values (was 3)\n",
    "    'clf__validation_fraction': [0.1]                 # 1 value (was 2)\n",
    "}\n",
    "\n",
    "# Run hyperparameter optimization using GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=full_pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',        # Main leaderboard metric\n",
    "    cv=5,                      # 5-fold cross-validation\n",
    "    n_jobs=-1,                 # Parallel execution\n",
    "    verbose=1,                 # Print progress\n",
    "    return_train_score=True    # Track training performance\n",
    ")\n",
    "\n",
    "# Fit the pipeline to training data\n",
    "start_time = datetime.now()\n",
    "grid_search.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "# Print best result and CV performance\n",
    "print(\"üéØ Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"\\n‚úÖ Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Extract all grid search results for tracking\n",
    "cv_results = grid_search.cv_results_\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(cv_results['params'])):\n",
    "    # Extract hyperparameters\n",
    "    params = cv_results['params'][i]\n",
    "    clean_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
    "\n",
    "    # Get CV scores for each fold\n",
    "    cv_scores = []\n",
    "    for fold in range(5):\n",
    "        cv_scores.append(cv_results[f'split{fold}_test_score'][i])\n",
    "\n",
    "    # Create result record\n",
    "    result = {\n",
    "        'Model': 'GradientBoosting',\n",
    "        'Hyperparameters': str(clean_params),\n",
    "        'CV_Accuracy_Mean': cv_results['mean_test_score'][i],\n",
    "        'CV_Accuracy_Std': cv_results['std_test_score'][i],\n",
    "        'CV_Accuracy_Min': min(cv_scores),\n",
    "        'CV_Accuracy_Max': max(cv_scores),\n",
    "        'Rank': cv_results['rank_test_score'][i],\n",
    "        'Is_Best': i == grid_search.best_index_,\n",
    "        'Runtime_Seconds': (end_time - start_time).total_seconds()\n",
    "    }\n",
    "\n",
    "    # Add individual hyperparameters as separate columns\n",
    "    for param_name, param_value in clean_params.items():\n",
    "        result[f'{param_name}'] = param_value\n",
    "\n",
    "    results_list.append(result)\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display top 10 configurations\n",
    "print(\"\\nüìä TOP 10 CONFIGURATIONS:\")\n",
    "top_configs = results_df.nlargest(10, 'CV_Accuracy_Mean')[\n",
    "    ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'Hyperparameters', 'Rank']\n",
    "]\n",
    "print(top_configs.to_string(index=False))\n",
    "\n",
    "# Show accuracy range\n",
    "print(f\"\\nüìà PERFORMANCE SUMMARY:\")\n",
    "print(f\"Total experiments: {len(results_df)}\")\n",
    "print(f\"Best CV Accuracy: {results_df['CV_Accuracy_Mean'].max():.4f}\")\n",
    "print(f\"Worst CV Accuracy: {results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
    "print(f\"Accuracy Range: {results_df['CV_Accuracy_Mean'].max() - results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
    "print(f\"Total Runtime: {(end_time - start_time).total_seconds():.2f} seconds\")\n",
    "\n",
    "# Save results to CSV\n",
    "results_df.to_csv('gradientboosting_grid_search_results.csv', index=False)\n",
    "print(f\"\\nüíæ Results saved to: gradientboosting_grid_search_results.csv\")\n",
    "\n",
    "# Extract best model for reuse or export\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, 'best_gradientboosting_grid_model.pkl')\n",
    "print(\"‚úÖ Best model saved to: best_gradientboosting_grid_model.pkl\")\n",
    "\n",
    "# Display detailed results table\n",
    "print(f\"\\nüìã DETAILED RESULTS TABLE:\")\n",
    "display_cols = ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'n_estimators', 'max_depth', 'learning_rate', 'subsample', 'min_samples_split', 'Rank']\n",
    "# results_df[display_cols].round(2).head(15)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "e1fb3e75cfaf4eac98c30f1b650f9f61",
      "0dc4b7c5f9374c91a345eb9a8cff52f1",
      "675f971bb3474886b7e2937e9abbe924",
      "042cc973049b4bd38dd76ed12673c5ed",
      "990c81edd0cd45f2b51a64c6939eb5b3",
      "1493091bac6f4b3e939ca5fa8f8c75de",
      "c857c51c01234807b969b64c5a82cbff",
      "52b470330cee4f0ca7841bb18d0d40ab",
      "67f26fc4f3de4c28b1fbe26f2f100f72",
      "eca2bff412c64b2386a0a795c398cb6f",
      "32977e762de24e1cadad3b95f787753f"
     ]
    },
    "id": "Cb6E9fAmhD1J",
    "outputId": "a1623e1c-4e84-4c36-b8be-fb7c36034488",
    "ExecuteTime": {
     "end_time": "2025-06-06T20:19:28.492253Z",
     "start_time": "2025-06-06T20:18:27.325944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "üéØ Best Hyperparameters:\n",
      "{'clf__learning_rate': 0.08, 'clf__max_depth': 3, 'clf__max_features': 0.8, 'clf__min_samples_leaf': 4, 'clf__min_samples_split': 18, 'clf__n_estimators': 250, 'clf__subsample': 0.85, 'clf__validation_fraction': 0.1}\n",
      "\n",
      "‚úÖ Best CV Accuracy: 0.7994\n",
      "\n",
      "üìä TOP 10 CONFIGURATIONS:\n",
      "           Model  CV_Accuracy_Mean  CV_Accuracy_Std                                                                                                                                                                     Hyperparameters  Rank\n",
      "GradientBoosting          0.799382         0.013031    {'learning_rate': 0.08, 'max_depth': 3, 'max_features': 0.8, 'min_samples_leaf': 4, 'min_samples_split': 18, 'n_estimators': 250, 'subsample': 0.85, 'validation_fraction': 0.1}     1\n",
      "GradientBoosting          0.799267         0.012084    {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 0.8, 'min_samples_leaf': 4, 'min_samples_split': 18, 'n_estimators': 250, 'subsample': 0.85, 'validation_fraction': 0.1}     2\n",
      "GradientBoosting          0.798922         0.011946 {'learning_rate': 0.06, 'max_depth': 4, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 18, 'n_estimators': 250, 'subsample': 0.95, 'validation_fraction': 0.1}     3\n",
      "GradientBoosting          0.798807         0.012648 {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 12, 'n_estimators': 350, 'subsample': 0.85, 'validation_fraction': 0.1}     4\n",
      "GradientBoosting          0.798577         0.011637 {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 8, 'min_samples_split': 18, 'n_estimators': 350, 'subsample': 0.95, 'validation_fraction': 0.1}     5\n",
      "GradientBoosting          0.798462         0.012966 {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 12, 'n_estimators': 350, 'subsample': 0.85, 'validation_fraction': 0.1}     6\n",
      "GradientBoosting          0.798462         0.011839    {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 0.8, 'min_samples_leaf': 8, 'min_samples_split': 18, 'n_estimators': 250, 'subsample': 0.85, 'validation_fraction': 0.1}     7\n",
      "GradientBoosting          0.798461         0.010431    {'learning_rate': 0.08, 'max_depth': 3, 'max_features': 0.8, 'min_samples_leaf': 4, 'min_samples_split': 12, 'n_estimators': 350, 'subsample': 0.85, 'validation_fraction': 0.1}     8\n",
      "GradientBoosting          0.798461         0.010528    {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 0.8, 'min_samples_leaf': 4, 'min_samples_split': 12, 'n_estimators': 350, 'subsample': 0.85, 'validation_fraction': 0.1}     9\n",
      "GradientBoosting          0.798347         0.012440 {'learning_rate': 0.06, 'max_depth': 3, 'max_features': 'log2', 'min_samples_leaf': 4, 'min_samples_split': 12, 'n_estimators': 350, 'subsample': 0.95, 'validation_fraction': 0.1}    10\n",
      "\n",
      "üìà PERFORMANCE SUMMARY:\n",
      "Total experiments: 128\n",
      "Best CV Accuracy: 0.7994\n",
      "Worst CV Accuracy: 0.7925\n",
      "Accuracy Range: 0.0069\n",
      "Total Runtime: 61.14 seconds\n",
      "\n",
      "üíæ Results saved to: gradientboosting_grid_search_results.csv\n",
      "‚úÖ Best model saved to: best_gradientboosting_grid_model.pkl\n",
      "\n",
      "üìã DETAILED RESULTS TABLE:\n",
      "CPU times: user 1.53 s, sys: 302 ms, total: 1.84 s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-06T20:19:28.550720Z",
     "start_time": "2025-06-06T20:19:28.522392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ================================================================\n",
    "# SUMMARY: TOP PERFORMING MODELS COMPARISON\n",
    "# ================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ GRID SEARCH OPTIMIZATION SUMMARY - BEST SELECTED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load results from each model\n",
    "xgb_results = pd.read_csv('../results/xgboost_grid_search_results.csv')\n",
    "cat_results = pd.read_csv('../results/catboost_grid_search_results.csv')\n",
    "gb_results = pd.read_csv('gradientboosting_grid_search_results.csv')\n",
    "\n",
    "# Extract best performance from each model\n",
    "summary_data = []\n",
    "\n",
    "# XGBoost best\n",
    "xgb_best = xgb_results.loc[xgb_results['CV_Accuracy_Mean'].idxmax()]\n",
    "summary_data.append({\n",
    "    'Model': 'XGBoost',\n",
    "    'CV_Accuracy_Mean': xgb_best['CV_Accuracy_Mean'],\n",
    "    'CV_Accuracy_Std': xgb_best['CV_Accuracy_Std']\n",
    "})\n",
    "\n",
    "# CatBoost best\n",
    "cat_best = cat_results.loc[cat_results['CV_Accuracy_Mean'].idxmax()]\n",
    "summary_data.append({\n",
    "    'Model': 'CatBoost',\n",
    "    'CV_Accuracy_Mean': cat_best['CV_Accuracy_Mean'],\n",
    "    'CV_Accuracy_Std': cat_best['CV_Accuracy_Std']\n",
    "})\n",
    "\n",
    "# Gradient Boosting best\n",
    "gb_best = gb_results.loc[gb_results['CV_Accuracy_Mean'].idxmax()]\n",
    "summary_data.append({\n",
    "    'Model': 'GradientBoosting',\n",
    "    'CV_Accuracy_Mean': gb_best['CV_Accuracy_Mean'],\n",
    "    'CV_Accuracy_Std': gb_best['CV_Accuracy_Std']\n",
    "})\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary_df = pd.DataFrame(summary_data).sort_values('CV_Accuracy_Mean', ascending=False)\n",
    "\n",
    "# Display summary\n",
    "print(\"üìä BEST PERFORMANCE FROM EACH MODEL:\")\n",
    "print(summary_df.round(4).to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('results/grid_search_summary.csv', index=False)\n",
    "print(f\"\\nüíæ Summary saved to: results/grid_search_summary.csv\")\n",
    "\n",
    "# Winner announcement\n",
    "winner = summary_df.iloc[0]\n",
    "print(f\"\\nüèÜ GRID SEARCH WINNER: {winner['Model']}\")\n",
    "print(f\"üèÜ Best CV Accuracy: {winner['CV_Accuracy_Mean']:.4f} (¬±{winner['CV_Accuracy_Std']:.4f})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üèÜ GRID SEARCH OPTIMIZATION SUMMARY - BEST SELECTED FEATURES\n",
      "============================================================\n",
      "üìä BEST PERFORMANCE FROM EACH MODEL:\n",
      "           Model  CV_Accuracy_Mean  CV_Accuracy_Std\n",
      "        CatBoost            0.8016           0.0163\n",
      "         XGBoost            0.7997           0.0102\n",
      "GradientBoosting            0.7994           0.0130\n",
      "\n",
      "üíæ Summary saved to: results/grid_search_summary.csv\n",
      "\n",
      "üèÜ GRID SEARCH WINNER: CatBoost\n",
      "üèÜ Best CV Accuracy: 0.8016 (¬±0.0163)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
