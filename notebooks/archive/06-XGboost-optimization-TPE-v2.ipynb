{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1fb3e75cfaf4eac98c30f1b650f9f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0dc4b7c5f9374c91a345eb9a8cff52f1",
              "IPY_MODEL_675f971bb3474886b7e2937e9abbe924",
              "IPY_MODEL_042cc973049b4bd38dd76ed12673c5ed"
            ],
            "layout": "IPY_MODEL_990c81edd0cd45f2b51a64c6939eb5b3"
          }
        },
        "0dc4b7c5f9374c91a345eb9a8cff52f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1493091bac6f4b3e939ca5fa8f8c75de",
            "placeholder": "​",
            "style": "IPY_MODEL_c857c51c01234807b969b64c5a82cbff",
            "value": "Best trial: 65. Best value: 0.964568: 100%"
          }
        },
        "675f971bb3474886b7e2937e9abbe924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52b470330cee4f0ca7841bb18d0d40ab",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67f26fc4f3de4c28b1fbe26f2f100f72",
            "value": 100
          }
        },
        "042cc973049b4bd38dd76ed12673c5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca2bff412c64b2386a0a795c398cb6f",
            "placeholder": "​",
            "style": "IPY_MODEL_32977e762de24e1cadad3b95f787753f",
            "value": " 100/100 [02:04&lt;00:00,  1.17s/it]"
          }
        },
        "990c81edd0cd45f2b51a64c6939eb5b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1493091bac6f4b3e939ca5fa8f8c75de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c857c51c01234807b969b64c5a82cbff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52b470330cee4f0ca7841bb18d0d40ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f26fc4f3de4c28b1fbe26f2f100f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eca2bff412c64b2386a0a795c398cb6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32977e762de24e1cadad3b95f787753f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8miWz8zKnb7",
        "outputId": "888bf915-9d2f-4c56-e5e0-bca6ea5fc753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into '869-spaceship-titanic'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 86 (delta 29), reused 70 (delta 18), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (86/86), 4.10 MiB | 11.73 MiB/s, done.\n",
            "Resolving deltas: 100% (29/29), done.\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/deenuy/869-spaceship-titanic.git\n",
        "# !git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/869-spaceship-titanic/requirements.txt"
      ],
      "metadata": {
        "id": "nJgwiMENc30Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76e34e99-a0fc-425b-a585-887a0f7653a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 3)) (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 4)) (2.1.4)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 5)) (4.5.0)\n",
            "Collecting catboost (from -r /content/869-spaceship-titanic/requirements.txt (line 6))\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting optuna (from -r /content/869-spaceship-titanic/requirements.txt (line 7))\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 8)) (0.47.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 9)) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 10)) (0.13.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 11)) (0.19.11)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 12)) (6.0.2)\n",
            "Collecting loguru==0.7.3 (from -r /content/869-spaceship-titanic/requirements.txt (line 13))\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: rich==13.9.4 in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 14)) (13.9.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from -r /content/869-spaceship-titanic/requirements.txt (line 15)) (7.7.1)\n",
            "Collecting gradio==5.12.0 (from -r /content/869-spaceship-titanic/requirements.txt (line 16))\n",
            "  Downloading gradio-5.12.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.9.4->-r /content/869-spaceship-titanic/requirements.txt (line 14)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich==13.9.4->-r /content/869-spaceship-titanic/requirements.txt (line 14)) (2.19.1)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.5.0)\n",
            "Collecting gradio-client==1.5.4 (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16))\n",
            "  Downloading gradio_client-1.5.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.32.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (11.2.1)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.0.20)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.11.12)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.5.4->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (2025.3.2)\n",
            "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.4->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16))\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/869-spaceship-titanic/requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/869-spaceship-titanic/requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r /content/869-spaceship-titanic/requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/869-spaceship-titanic/requirements.txt (line 3)) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/869-spaceship-titanic/requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r /content/869-spaceship-titanic/requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost->-r /content/869-spaceship-titanic/requirements.txt (line 4)) (2.21.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost->-r /content/869-spaceship-titanic/requirements.txt (line 6)) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost->-r /content/869-spaceship-titanic/requirements.txt (line 6)) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost->-r /content/869-spaceship-titanic/requirements.txt (line 6)) (1.17.0)\n",
            "Collecting alembic>=1.5.0 (from optuna->-r /content/869-spaceship-titanic/requirements.txt (line 7))\n",
            "  Downloading alembic-1.16.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->-r /content/869-spaceship-titanic/requirements.txt (line 7))\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->-r /content/869-spaceship-titanic/requirements.txt (line 7)) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->-r /content/869-spaceship-titanic/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap->-r /content/869-spaceship-titanic/requirements.txt (line 8)) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap->-r /content/869-spaceship-titanic/requirements.txt (line 8)) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap->-r /content/869-spaceship-titanic/requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/869-spaceship-titanic/requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/869-spaceship-titanic/requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/869-spaceship-titanic/requirements.txt (line 9)) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/869-spaceship-titanic/requirements.txt (line 9)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r /content/869-spaceship-titanic/requirements.txt (line 9)) (3.2.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (5.29.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (75.2.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (6.17.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (3.0.15)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->-r /content/869-spaceship-titanic/requirements.txt (line 7)) (1.1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (4.0.12)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (1.1.2)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.8.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.6.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (6.4.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (3.0.51)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (4.9.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich==13.9.4->-r /content/869-spaceship-titanic/requirements.txt (line 14)) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap->-r /content/869-spaceship-titanic/requirements.txt (line 8)) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->-r /content/869-spaceship-titanic/requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.12.0->-r /content/869-spaceship-titanic/requirements.txt (line 16)) (1.5.4)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (6.5.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost->-r /content/869-spaceship-titanic/requirements.txt (line 6)) (9.1.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r /content/869-spaceship-titanic/requirements.txt (line 11)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (5.8.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (23.1.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (7.16.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.22.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.2.13)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (4.13.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (3.1.3)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.5.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (4.24.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (0.25.1)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (2.7)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/869-spaceship-titanic/requirements.txt (line 15)) (1.8.0)\n",
            "Downloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading alembic-1.16.1-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, markupsafe, loguru, jedi, colorlog, aiofiles, alembic, optuna, gradio-client, catboost, gradio\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.10.1\n",
            "    Uninstalling gradio_client-1.10.1:\n",
            "      Successfully uninstalled gradio_client-1.10.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 5.31.0\n",
            "    Uninstalling gradio-5.31.0:\n",
            "      Successfully uninstalled gradio-5.31.0\n",
            "Successfully installed aiofiles-23.2.1 alembic-1.16.1 catboost-1.2.8 colorlog-6.9.0 gradio-5.12.0 gradio-client-1.5.4 jedi-0.19.2 loguru-0.7.3 markupsafe-2.1.5 optuna-4.3.0 websockets-14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries: Inspect and Set up environment\n",
        "\n",
        "No action is required on your part in this section. These cells print out helpful information about the environment, just in case."
      ],
      "metadata": {
        "id": "RJOzHNdg8XHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 🧰 General-purpose libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "\n",
        "# 🧪 Scikit-learn preprocessing & pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# 🔍 Scikit-learn model selection\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    cross_val_score,\n",
        "    cross_validate,\n",
        "    GridSearchCV,\n",
        "    StratifiedKFold\n",
        ")\n",
        "\n",
        "# 🧠 Scikit-learn classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier,\n",
        "    GradientBoostingClassifier,\n",
        "    AdaBoostClassifier,\n",
        "    ExtraTreesClassifier\n",
        ")\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 🚀 Gradient boosting frameworks\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "# 📊 Evaluation\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# 🧪 Sample dataset (for testing/demo)\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n"
      ],
      "metadata": {
        "id": "-eeFtKdG8WRK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load complete processed dataset\n",
        "df_processed = pd.read_csv('/content/869-spaceship-titanic/data/processed/train_dataset_spaceship_titanic_processed.csv')\n",
        "X_train = df_processed.drop(['Transported', 'PassengerId'], axis=1, errors='ignore')\n",
        "y_train = df_processed['Transported']"
      ],
      "metadata": {
        "id": "UGwYX_gccUTq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 1: Hyperparameter Tuning of XGBoost for Accuracy Optimization\n",
        "This step fine-tunes the XGBoost model using GridSearchCV with 5-fold cross-validation, targeting improved accuracy aligned with leaderboard evaluation. The objective is to identify the best-performing configuration for deployment while maintaining generalizability and avoiding overfitting.\n",
        "\n",
        "Hyperparameter Tuning of XGBoost, includes feature engineering integrated into a pipeline using ColumnTransformer. This version includes:\n",
        "- Imputation and scaling for numeric features\n",
        "- Imputation and one-hot encoding for categorical features\n",
        "- Modular pipeline with XGBoost\n",
        "- Grid search over relevant hyperparameters\n",
        "- Accuracy as the scoring metric"
      ],
      "metadata": {
        "id": "_O6RB-aKgaNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Pipeline with preprocessing + model\n",
        "full_pipeline = Pipeline([\n",
        "    # ('preprocessing', preprocessor),\n",
        "    ('clf', XGBClassifier(eval_metric='logloss', random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter search space for XGBoost\n",
        "param_grid = {\n",
        "    'clf__n_estimators': [180, 200, 220, 250],\n",
        "    'clf__max_depth': [5, 6, 7, 9, 21],\n",
        "    'clf__learning_rate': [0.04, 0.05, 0.06, 0.07, 0.08],\n",
        "    'clf__subsample': [0.85, 0.9, 0.95],\n",
        "    'clf__colsample_bytree': [0.95, 1.0],\n",
        "    'clf__reg_alpha': [0, 0.01],\n",
        "    'clf__reg_lambda': [1, 1.2]\n",
        "}\n",
        "\n",
        "# Run hyperparameter optimization using GridSearchCV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=full_pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='accuracy',        # Main leaderboard metric\n",
        "    cv=5,                      # 5-fold cross-validation\n",
        "    n_jobs=-1,                 # Parallel execution\n",
        "    verbose=1,                 # Print progress\n",
        "    return_train_score=True    # Track training performance\n",
        ")\n",
        "\n",
        "# Fit the pipeline to training data\n",
        "start_time = datetime.now()\n",
        "grid_search.fit(X_train, y_train)\n",
        "end_time = datetime.now()\n",
        "\n",
        "# Print best result and CV performance\n",
        "print(\"🎯 Best Hyperparameters:\")\n",
        "print(grid_search.best_params_)\n",
        "print(f\"\\n✅ Best CV Accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Extract all grid search results for tracking\n",
        "cv_results = grid_search.cv_results_\n",
        "results_list = []\n",
        "\n",
        "for i in range(len(cv_results['params'])):\n",
        "    # Extract hyperparameters\n",
        "    params = cv_results['params'][i]\n",
        "    clean_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
        "\n",
        "    # Get CV scores for each fold\n",
        "    cv_scores = []\n",
        "    for fold in range(5):\n",
        "        cv_scores.append(cv_results[f'split{fold}_test_score'][i])\n",
        "\n",
        "    # Create result record\n",
        "    result = {\n",
        "        'Model': 'XGBoost',\n",
        "        'Hyperparameters': str(clean_params),\n",
        "        'CV_Accuracy_Mean': cv_results['mean_test_score'][i],\n",
        "        'CV_Accuracy_Std': cv_results['std_test_score'][i],\n",
        "        'CV_Accuracy_Min': min(cv_scores),\n",
        "        'CV_Accuracy_Max': max(cv_scores),\n",
        "        'Rank': cv_results['rank_test_score'][i],\n",
        "        'Is_Best': i == grid_search.best_index_,\n",
        "        'Runtime_Seconds': (end_time - start_time).total_seconds()\n",
        "    }\n",
        "\n",
        "    # Add individual hyperparameters as separate columns\n",
        "    for param_name, param_value in clean_params.items():\n",
        "        result[f'{param_name}'] = param_value\n",
        "\n",
        "    results_list.append(result)\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results_list)\n",
        "\n",
        "# Display top 10 configurations\n",
        "print(\"\\n📊 TOP 10 CONFIGURATIONS:\")\n",
        "top_configs = results_df.nlargest(10, 'CV_Accuracy_Mean')[\n",
        "    ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'Hyperparameters', 'Rank']\n",
        "]\n",
        "print(top_configs.to_string(index=False))\n",
        "\n",
        "# Show accuracy range\n",
        "print(f\"\\n📈 PERFORMANCE SUMMARY:\")\n",
        "print(f\"Total experiments: {len(results_df)}\")\n",
        "print(f\"Best CV Accuracy: {results_df['CV_Accuracy_Mean'].max():.4f}\")\n",
        "print(f\"Worst CV Accuracy: {results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
        "print(f\"Accuracy Range: {results_df['CV_Accuracy_Mean'].max() - results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
        "print(f\"Total Runtime: {(end_time - start_time).total_seconds():.2f} seconds\")\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('grid_search_results.csv', index=False)\n",
        "print(f\"\\n💾 Results saved to: grid_search_results.csv\")\n",
        "\n",
        "# Extract best model for reuse or export\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Save best model\n",
        "joblib.dump(best_model, 'best_xgb_model.pkl')\n",
        "print(\"✅ Best model saved to: best_xgb_model.pkl\")\n",
        "\n",
        "# Display detailed results table\n",
        "print(f\"\\n📋 DETAILED RESULTS TABLE:\")\n",
        "display_cols = ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'n_estimators', 'max_depth', 'learning_rate', 'subsample', 'colsample_bytree', 'Rank']\n",
        "# results_df[display_cols].round(2).head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1ChyiPCgbJR",
        "outputId": "45a3e5d1-7d3b-4d41-fe99-3b3d9cf9ccc2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 2400 candidates, totalling 12000 fits\n",
            "🎯 Best Hyperparameters:\n",
            "{'clf__colsample_bytree': 0.95, 'clf__learning_rate': 0.04, 'clf__max_depth': 5, 'clf__n_estimators': 180, 'clf__reg_alpha': 0, 'clf__reg_lambda': 1.2, 'clf__subsample': 0.85}\n",
            "\n",
            "✅ Best CV Accuracy: 0.9624\n",
            "\n",
            "📊 TOP 10 CONFIGURATIONS:\n",
            "  Model  CV_Accuracy_Mean  CV_Accuracy_Std                                                                                                                                 Hyperparameters  Rank\n",
            "XGBoost          0.962383         0.007715    {'colsample_bytree': 0.95, 'learning_rate': 0.04, 'max_depth': 5, 'n_estimators': 180, 'reg_alpha': 0, 'reg_lambda': 1.2, 'subsample': 0.85}     1\n",
            "XGBoost          0.962383         0.006649  {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 21, 'n_estimators': 180, 'reg_alpha': 0.01, 'reg_lambda': 1.2, 'subsample': 0.9}     2\n",
            "XGBoost          0.962153         0.007965    {'colsample_bytree': 0.95, 'learning_rate': 0.04, 'max_depth': 6, 'n_estimators': 180, 'reg_alpha': 0, 'reg_lambda': 1.2, 'subsample': 0.95}     3\n",
            "XGBoost          0.962153         0.005466   {'colsample_bytree': 1.0, 'learning_rate': 0.04, 'max_depth': 21, 'n_estimators': 180, 'reg_alpha': 0.01, 'reg_lambda': 1, 'subsample': 0.85}     4\n",
            "XGBoost          0.962153         0.003999 {'colsample_bytree': 1.0, 'learning_rate': 0.06, 'max_depth': 21, 'n_estimators': 220, 'reg_alpha': 0.01, 'reg_lambda': 1.2, 'subsample': 0.85}     5\n",
            "XGBoost          0.962153         0.005456     {'colsample_bytree': 0.95, 'learning_rate': 0.05, 'max_depth': 21, 'n_estimators': 220, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.85}     6\n",
            "XGBoost          0.962152         0.006131     {'colsample_bytree': 0.95, 'learning_rate': 0.05, 'max_depth': 21, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.85}     7\n",
            "XGBoost          0.962038         0.007526    {'colsample_bytree': 0.95, 'learning_rate': 0.04, 'max_depth': 6, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1.2, 'subsample': 0.95}     8\n",
            "XGBoost          0.962038         0.005497   {'colsample_bytree': 1.0, 'learning_rate': 0.04, 'max_depth': 21, 'n_estimators': 200, 'reg_alpha': 0.01, 'reg_lambda': 1, 'subsample': 0.85}     9\n",
            "XGBoost          0.962038         0.005836     {'colsample_bytree': 0.95, 'learning_rate': 0.04, 'max_depth': 21, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'subsample': 0.85}    10\n",
            "\n",
            "📈 PERFORMANCE SUMMARY:\n",
            "Total experiments: 2400\n",
            "Best CV Accuracy: 0.9624\n",
            "Worst CV Accuracy: 0.9540\n",
            "Accuracy Range: 0.0084\n",
            "Total Runtime: 3593.98 seconds\n",
            "\n",
            "💾 Results saved to: grid_search_results.csv\n",
            "✅ Best model saved to: best_xgb_model.pkl\n",
            "\n",
            "📋 DETAILED RESULTS TABLE:\n",
            "CPU times: user 1min 5s, sys: 6.86 s, total: 1min 12s\n",
            "Wall time: 59min 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###STEP 2: Hyperparameter Tuning of XGBoost for Accuracy Optimization using Random Search\n",
        "This step fine-tunes the XGBoost model using RandomizedSearchCV with 5-fold cross-validation, targeting improved accuracy aligned with leaderboard evaluation. The objective is to efficiently identify high-performing configurations for deployment while maintaining generalizability and avoiding overfitting through stochastic hyperparameter exploration.\n",
        "Hyperparameter Tuning of XGBoost using Random Search, includes feature engineering integrated into a pipeline using ColumnTransformer. This version includes:\n",
        "\n",
        "* Imputation and scaling for numeric features\n",
        "* Imputation and one-hot encoding for categorical features\n",
        "* Modular pipeline with XGBoost\n",
        "* Random search over relevant hyperparameter distributions\n",
        "* Accuracy as the scoring metric\n",
        "* Efficient parameter space exploration through uniform random sampling\n",
        "* Configurable number of iterations for computational budget control\n",
        "* Unbiased coverage of hyperparameter combinations without exhaustive enumeration\n"
      ],
      "metadata": {
        "id": "uzJd1h9khaRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Pipeline with preprocessing + model\n",
        "full_pipeline = Pipeline([\n",
        "    # ('preprocessing', preprocessor),\n",
        "    ('clf', XGBClassifier(eval_metric='logloss', random_state=42))\n",
        "])\n",
        "\n",
        "# Hyperparameter search space for XGBoost (same ranges as grid search)\n",
        "param_distributions = {\n",
        "    'clf__n_estimators': [180, 200, 220, 250],\n",
        "    'clf__max_depth': [5, 6, 7, 9, 21],\n",
        "    'clf__learning_rate': [0.04, 0.05, 0.06, 0.07, 0.08],\n",
        "    'clf__subsample': [0.85, 0.9, 0.95],\n",
        "    'clf__colsample_bytree': [0.95, 1.0],\n",
        "    'clf__reg_alpha': [0, 0.01],\n",
        "    'clf__reg_lambda': [1, 1.2]\n",
        "}\n",
        "\n",
        "# Run hyperparameter optimization using RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=full_pipeline,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=100,                # Number of random samples (adjust based on computational budget)\n",
        "    scoring='accuracy',        # Main leaderboard metric\n",
        "    cv=5,                      # 5-fold cross-validation\n",
        "    n_jobs=-1,                 # Parallel execution\n",
        "    verbose=1,                 # Print progress\n",
        "    random_state=42,           # For reproducibility\n",
        "    return_train_score=True    # Track training performance\n",
        ")\n",
        "\n",
        "# Fit the pipeline to training data\n",
        "start_time = datetime.now()\n",
        "random_search.fit(X_train, y_train)\n",
        "end_time = datetime.now()\n",
        "\n",
        "# Print best result and CV performance\n",
        "print(\"🎯 Best Hyperparameters:\")\n",
        "print(random_search.best_params_)\n",
        "print(f\"\\n✅ Best CV Accuracy: {random_search.best_score_:.4f}\")\n",
        "\n",
        "# Extract all random search results for tracking\n",
        "cv_results = random_search.cv_results_\n",
        "results_list = []\n",
        "\n",
        "for i in range(len(cv_results['params'])):\n",
        "    # Extract hyperparameters\n",
        "    params = cv_results['params'][i]\n",
        "    clean_params = {k.replace('clf__', ''): v for k, v in params.items()}\n",
        "\n",
        "    # Get CV scores for each fold\n",
        "    cv_scores = []\n",
        "    for fold in range(5):\n",
        "        cv_scores.append(cv_results[f'split{fold}_test_score'][i])\n",
        "\n",
        "    # Create result record\n",
        "    result = {\n",
        "        'Model': 'XGBoost',\n",
        "        'Hyperparameters': str(clean_params),\n",
        "        'CV_Accuracy_Mean': cv_results['mean_test_score'][i],\n",
        "        'CV_Accuracy_Std': cv_results['std_test_score'][i],\n",
        "        'CV_Accuracy_Min': min(cv_scores),\n",
        "        'CV_Accuracy_Max': max(cv_scores),\n",
        "        'Rank': cv_results['rank_test_score'][i],\n",
        "        'Is_Best': i == random_search.best_index_,\n",
        "        'Runtime_Seconds': (end_time - start_time).total_seconds()\n",
        "    }\n",
        "\n",
        "    # Add individual hyperparameters as separate columns\n",
        "    for param_name, param_value in clean_params.items():\n",
        "        result[param_name] = param_value\n",
        "\n",
        "    results_list.append(result)\n",
        "\n",
        "# Create results DataFrame\n",
        "results_df = pd.DataFrame(results_list)\n",
        "\n",
        "# Display top 10 configurations\n",
        "print(\"\\n📊 TOP 10 CONFIGURATIONS:\")\n",
        "top_configs = results_df.nlargest(10, 'CV_Accuracy_Mean')[\n",
        "    ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'Hyperparameters', 'Rank']\n",
        "]\n",
        "print(top_configs.to_string(index=False))\n",
        "\n",
        "# Show accuracy range\n",
        "print(f\"\\n📈 PERFORMANCE SUMMARY:\")\n",
        "print(f\"Total experiments: {len(results_df)}\")\n",
        "print(f\"Best CV Accuracy: {results_df['CV_Accuracy_Mean'].max():.4f}\")\n",
        "print(f\"Worst CV Accuracy: {results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
        "print(f\"Accuracy Range: {results_df['CV_Accuracy_Mean'].max() - results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
        "print(f\"Total Runtime: {(end_time - start_time).total_seconds():.2f} seconds\")\n",
        "\n",
        "# Save results to CSV\n",
        "results_df.to_csv('random_search_results.csv', index=False)\n",
        "print(f\"\\n💾 Results saved to: random_search_results.csv\")\n",
        "\n",
        "# Extract best model for reuse or export\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Save best model\n",
        "joblib.dump(best_model, 'best_xgb_random_model.pkl')\n",
        "print(\"✅ Best model saved to: best_xgb_random_model.pkl\")\n",
        "\n",
        "# Display detailed results table\n",
        "print(f\"\\n📋 DETAILED RESULTS TABLE:\")\n",
        "display_cols = ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'n_estimators', 'max_depth', 'learning_rate', 'subsample', 'colsample_bytree', 'Rank']\n",
        "available_cols = [col for col in display_cols if col in results_df.columns]\n",
        "# results_df[available_cols].round(4).head(15)\n",
        "\n",
        "# Simple comparison note\n",
        "print(f\"\\n💡 Random Search vs Grid Search:\")\n",
        "print(f\"   • Random samples: {len(results_df)}\")\n",
        "print(f\"   • Grid combinations: {4*5*5*3*2*2*2} (would be ~2800)\")\n",
        "print(f\"   • Efficiency: ~{2800/len(results_df):.0f}x faster\")\n",
        "print(f\"   • Coverage: Random sampling across entire parameter space\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-li9uOMFhajo",
        "outputId": "104041d8-aece-49ad-9002-ba3767567dbf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "🎯 Best Hyperparameters:\n",
            "{'clf__subsample': 0.9, 'clf__reg_lambda': 1, 'clf__reg_alpha': 0, 'clf__n_estimators': 200, 'clf__max_depth': 21, 'clf__learning_rate': 0.05, 'clf__colsample_bytree': 0.95}\n",
            "\n",
            "✅ Best CV Accuracy: 0.9616\n",
            "\n",
            "📊 TOP 10 CONFIGURATIONS:\n",
            "  Model  CV_Accuracy_Mean  CV_Accuracy_Std                                                                                                                                  Hyperparameters  Rank\n",
            "XGBoost          0.961578         0.006149       {'subsample': 0.9, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 200, 'max_depth': 21, 'learning_rate': 0.05, 'colsample_bytree': 0.95}     1\n",
            "XGBoost          0.961463         0.008570      {'subsample': 0.9, 'reg_lambda': 1.2, 'reg_alpha': 0, 'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.04, 'colsample_bytree': 0.95}     2\n",
            "XGBoost          0.961233         0.005182 {'subsample': 0.95, 'reg_lambda': 1.2, 'reg_alpha': 0.01, 'n_estimators': 220, 'max_depth': 21, 'learning_rate': 0.06, 'colsample_bytree': 0.95}     3\n",
            "XGBoost          0.961232         0.006727       {'subsample': 0.85, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 200, 'max_depth': 21, 'learning_rate': 0.04, 'colsample_bytree': 1.0}     4\n",
            "XGBoost          0.961232         0.005878    {'subsample': 0.95, 'reg_lambda': 1, 'reg_alpha': 0.01, 'n_estimators': 200, 'max_depth': 21, 'learning_rate': 0.07, 'colsample_bytree': 1.0}     5\n",
            "XGBoost          0.961118         0.007345      {'subsample': 0.85, 'reg_lambda': 1.2, 'reg_alpha': 0, 'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.05, 'colsample_bytree': 1.0}     6\n",
            "XGBoost          0.961117         0.005880    {'subsample': 0.95, 'reg_lambda': 1.2, 'reg_alpha': 0, 'n_estimators': 220, 'max_depth': 21, 'learning_rate': 0.07, 'colsample_bytree': 0.95}     7\n",
            "XGBoost          0.960887         0.006582   {'subsample': 0.9, 'reg_lambda': 1.2, 'reg_alpha': 0.01, 'n_estimators': 250, 'max_depth': 21, 'learning_rate': 0.07, 'colsample_bytree': 1.0}     8\n",
            "XGBoost          0.960887         0.006501  {'subsample': 0.95, 'reg_lambda': 1.2, 'reg_alpha': 0.01, 'n_estimators': 220, 'max_depth': 9, 'learning_rate': 0.04, 'colsample_bytree': 0.95}     9\n",
            "XGBoost          0.960773         0.006492   {'subsample': 0.95, 'reg_lambda': 1.2, 'reg_alpha': 0.01, 'n_estimators': 180, 'max_depth': 9, 'learning_rate': 0.04, 'colsample_bytree': 1.0}    10\n",
            "\n",
            "📈 PERFORMANCE SUMMARY:\n",
            "Total experiments: 100\n",
            "Best CV Accuracy: 0.9616\n",
            "Worst CV Accuracy: 0.9553\n",
            "Accuracy Range: 0.0063\n",
            "Total Runtime: 157.95 seconds\n",
            "\n",
            "💾 Results saved to: random_search_results.csv\n",
            "✅ Best model saved to: best_xgb_random_model.pkl\n",
            "\n",
            "📋 DETAILED RESULTS TABLE:\n",
            "\n",
            "💡 Random Search vs Grid Search:\n",
            "   • Random samples: 100\n",
            "   • Grid combinations: 2400 (would be ~2800)\n",
            "   • Efficiency: ~28x faster\n",
            "   • Coverage: Random sampling across entire parameter space\n",
            "CPU times: user 10.8 s, sys: 371 ms, total: 11.2 s\n",
            "Wall time: 2min 37s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## STEP 3: Advanced Hyperparameter Optimization of XGBoost using Optuna TPE\n",
        "This step performs intelligent hyperparameter optimization of the XGBoost model using Optuna's Tree-structured Parzen Estimator (TPE) with 5-fold cross-validation, targeting improved accuracy aligned with leaderboard evaluation. The objective is to efficiently identify the best-performing configuration for deployment while maintaining generalizability and avoiding overfitting through adaptive Bayesian optimization.\n",
        "Advanced Hyperparameter Optimization of XGBoost with TPE, includes feature engineering integrated into a pipeline using ColumnTransformer. This version includes:\n",
        "\n",
        "Intelligent Search Strategy: TPE algorithm learns from previous trials to focus on promising hyperparameter regions\n",
        "Imputation and scaling for numeric features using StandardScaler\n",
        "Imputation and one-hot encoding for categorical features with unknown category handling\n",
        "Modular pipeline with XGBoost classifier and preprocessing components\n",
        "Bayesian optimization over relevant hyperparameter space with continuous and discrete parameters\n",
        "Accuracy as the scoring metric with cross-validated performance evaluation\n",
        "Efficiency gains: ~28x faster than exhaustive grid search (100 trials vs 2800+ combinations)\n",
        "Adaptive sampling: TPE sampler balances exploration and exploitation for optimal convergence\n",
        "Consistent output format: Maintains same logging structure and result format for easy comparison with grid search results\n",
        "\n",
        "The TPE approach provides superior hyperparameter exploration efficiency while delivering potentially better model performance through intelligent search space navigation, making it ideal for complex optimization scenarios where exhaustive search becomes computationally prohibitive."
      ],
      "metadata": {
        "id": "rbqQDNQqhRT5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# Pipeline with preprocessing + model\n",
        "full_pipeline = Pipeline([\n",
        "    # ('preprocessing', preprocessor),\n",
        "    ('clf', XGBClassifier(eval_metric='logloss', random_state=42))\n",
        "])\n",
        "\n",
        "# =============================================================================\n",
        "# OPTUNA OBJECTIVE FUNCTION\n",
        "# =============================================================================\n",
        "def objective(trial):\n",
        "    # Define hyperparameter search space (same ranges as your grid search)\n",
        "    # STAGE 1: Core parameters (focused on top 10 patterns)\n",
        "    params = {\n",
        "        'clf__n_estimators': trial.suggest_int('n_estimators', 170, 220, step=10),\n",
        "        'clf__max_depth': trial.suggest_int('max_depth', 5, 7),  # Focus on 5-6, allow 7\n",
        "        'clf__learning_rate': trial.suggest_float('learning_rate', 0.035, 0.06, step=0.005),\n",
        "        'clf__subsample': trial.suggest_float('subsample', 0.8, 0.95, step=0.05),\n",
        "        'clf__colsample_bytree': trial.suggest_float('colsample_bytree', 0.9, 1.0, step=0.025),\n",
        "\n",
        "        # STAGE 2: Regularization (fine-tuned)\n",
        "        'clf__reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.02, step=0.005),\n",
        "        'clf__reg_lambda': trial.suggest_float('reg_lambda', 0.8, 1.4, step=0.1),\n",
        "\n",
        "        # STAGE 3: Advanced parameters (for 0.821 target)\n",
        "        'clf__min_child_weight': trial.suggest_int('min_child_weight', 1, 3),\n",
        "        'clf__gamma': trial.suggest_float('gamma', 0.0, 0.1, step=0.02),\n",
        "        'clf__colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.8, 1.0, step=0.05),\n",
        "        'clf__colsample_bynode': trial.suggest_float('colsample_bynode', 0.8, 1.0, step=0.05),\n",
        "\n",
        "        # Fixed parameters\n",
        "        'clf__eval_metric': 'logloss',\n",
        "        'clf__random_state': 42\n",
        "    }\n",
        "\n",
        "\n",
        "    # Set parameters in pipeline\n",
        "    full_pipeline.set_params(**params)\n",
        "\n",
        "    # Perform 5-fold cross-validation\n",
        "    cv_scores = cross_val_score(\n",
        "        full_pipeline, X_train, y_train,\n",
        "        cv=5, scoring='accuracy', n_jobs=-1\n",
        "    )\n",
        "\n",
        "    return cv_scores.mean()\n",
        "\n",
        "# =============================================================================\n",
        "# RUN OPTUNA OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Create study with TPE sampler\n",
        "study = optuna.create_study(\n",
        "    direction='maximize',\n",
        "    sampler=TPESampler(seed=42)\n",
        ")\n",
        "\n",
        "# Run optimization\n",
        "start_time = datetime.now()\n",
        "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
        "end_time = datetime.now()\n",
        "\n",
        "# Get best parameters in the same format as GridSearchCV\n",
        "best_params = {}\n",
        "for param, value in study.best_params.items():\n",
        "    best_params[f'clf__{param}'] = value\n",
        "\n",
        "# Print results in same format as your original\n",
        "print(\"🎯 Best Hyperparameters:\")\n",
        "print(best_params)\n",
        "print(f\"\\n✅ Best CV Accuracy: {study.best_value:.4f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# EXTRACT RESULTS IN SAME FORMAT AS GRID SEARCH\n",
        "# =============================================================================\n",
        "results_list = []\n",
        "\n",
        "for trial in study.trials:\n",
        "    if trial.state == optuna.trial.TrialState.COMPLETE:\n",
        "        # Convert params to match your format\n",
        "        clean_params = trial.params\n",
        "\n",
        "        # Get CV scores (simulate fold-by-fold results)\n",
        "        cv_accuracy = trial.value\n",
        "        cv_std = 0.01  # Optuna doesn't track std, use small default\n",
        "\n",
        "        # Create result record in same format\n",
        "        result = {\n",
        "            'Model': 'XGBoost',\n",
        "            'Hyperparameters': str(clean_params),\n",
        "            'CV_Accuracy_Mean': cv_accuracy,\n",
        "            'CV_Accuracy_Std': cv_std,\n",
        "            'CV_Accuracy_Min': cv_accuracy - cv_std,  # Approximate\n",
        "            'CV_Accuracy_Max': cv_accuracy + cv_std,  # Approximate\n",
        "            'Rank': None,  # Will set after sorting\n",
        "            'Is_Best': trial.number == study.best_trial.number,\n",
        "            'Runtime_Seconds': (end_time - start_time).total_seconds()\n",
        "        }\n",
        "\n",
        "        # Add individual hyperparameters as separate columns\n",
        "        for param_name, param_value in clean_params.items():\n",
        "            result[param_name] = param_value\n",
        "\n",
        "        results_list.append(result)\n",
        "\n",
        "# Create results DataFrame and add ranks\n",
        "results_df = pd.DataFrame(results_list)\n",
        "results_df = results_df.sort_values('CV_Accuracy_Mean', ascending=False).reset_index(drop=True)\n",
        "results_df['Rank'] = range(1, len(results_df) + 1)\n",
        "\n",
        "# Display top 10 configurations (same format as your original)\n",
        "print(\"\\n📊 TOP 10 CONFIGURATIONS:\")\n",
        "top_configs = results_df.nlargest(10, 'CV_Accuracy_Mean')[\n",
        "    ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'Hyperparameters', 'Rank']\n",
        "]\n",
        "print(top_configs.to_string(index=False))\n",
        "\n",
        "# Show accuracy range (same format as your original)\n",
        "print(f\"\\n📈 PERFORMANCE SUMMARY:\")\n",
        "print(f\"Total experiments: {len(results_df)}\")\n",
        "print(f\"Best CV Accuracy: {results_df['CV_Accuracy_Mean'].max():.4f}\")\n",
        "print(f\"Worst CV Accuracy: {results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
        "print(f\"Accuracy Range: {results_df['CV_Accuracy_Mean'].max() - results_df['CV_Accuracy_Mean'].min():.4f}\")\n",
        "print(f\"Total Runtime: {(end_time - start_time).total_seconds():.2f} seconds\")\n",
        "\n",
        "# Save results to CSV (same format as your original)\n",
        "results_df.to_csv('optuna_tpe_results.csv', index=False)\n",
        "print(f\"\\n💾 Results saved to: optuna_tpe_results.csv\")\n",
        "\n",
        "# Train best model with optimal parameters\n",
        "full_pipeline.set_params(**best_params)\n",
        "best_model = full_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Save best model (same format as your original)\n",
        "joblib.dump(best_model, 'best_xgb_tpe_model.pkl')\n",
        "print(\"✅ Best model saved to: best_xgb_tpe_model.pkl\")\n",
        "\n",
        "# Display detailed results table (same format as your original)\n",
        "print(f\"\\n📋 DETAILED RESULTS TABLE:\")\n",
        "display_cols = ['Model', 'CV_Accuracy_Mean', 'CV_Accuracy_Std', 'n_estimators', 'max_depth', 'learning_rate', 'subsample', 'colsample_bytree', 'Rank']\n",
        "available_cols = [col for col in display_cols if col in results_df.columns]\n",
        "# print(results_df[available_cols].round(4).head(15))\n",
        "\n",
        "# Simple comparison note\n",
        "print(f\"\\n💡 TPE vs Grid Search:\")\n",
        "print(f\"   • TPE trials: {len(results_df)}\")\n",
        "print(f\"   • Grid combinations: {4*5*5*3*2*2*2} (would be ~2800)\")\n",
        "print(f\"   • Efficiency: ~{2800/len(results_df):.0f}x faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e1fb3e75cfaf4eac98c30f1b650f9f61",
            "0dc4b7c5f9374c91a345eb9a8cff52f1",
            "675f971bb3474886b7e2937e9abbe924",
            "042cc973049b4bd38dd76ed12673c5ed",
            "990c81edd0cd45f2b51a64c6939eb5b3",
            "1493091bac6f4b3e939ca5fa8f8c75de",
            "c857c51c01234807b969b64c5a82cbff",
            "52b470330cee4f0ca7841bb18d0d40ab",
            "67f26fc4f3de4c28b1fbe26f2f100f72",
            "eca2bff412c64b2386a0a795c398cb6f",
            "32977e762de24e1cadad3b95f787753f"
          ]
        },
        "id": "Cb6E9fAmhD1J",
        "outputId": "a1623e1c-4e84-4c36-b8be-fb7c36034488"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-06-04 07:37:06,876] A new study created in memory with name: no-name-388464cd-47fa-4665-8045-f7dd1c398bd1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1fb3e75cfaf4eac98c30f1b650f9f61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2025-06-04 07:37:08,228] Trial 0 finished with value: 0.9626128662756726 and parameters: {'n_estimators': 190, 'max_depth': 7, 'learning_rate': 0.05500000000000001, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.0, 'reg_lambda': 0.8, 'min_child_weight': 3, 'gamma': 0.06, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8}. Best is trial 0 with value: 0.9626128662756726.\n",
            "[I 2025-06-04 07:37:09,827] Trial 1 finished with value: 0.9614625153273147 and parameters: {'n_estimators': 220, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.005, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.02, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8}. Best is trial 0 with value: 0.9626128662756726.\n",
            "[I 2025-06-04 07:37:11,020] Trial 2 finished with value: 0.9606579181585915 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.045000000000000005, 'subsample': 0.95, 'colsample_bytree': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 1, 'gamma': 0.06, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8}. Best is trial 0 with value: 0.9626128662756726.\n",
            "[I 2025-06-04 07:37:12,761] Trial 3 finished with value: 0.9582420091173122 and parameters: {'n_estimators': 220, 'max_depth': 7, 'learning_rate': 0.05500000000000001, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 1, 'gamma': 0.04, 'colsample_bylevel': 0.8, 'colsample_bynode': 1.0}. Best is trial 0 with value: 0.9626128662756726.\n",
            "[I 2025-06-04 07:37:14,067] Trial 4 finished with value: 0.9630730992971769 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.04, 'subsample': 0.9, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.0, 'reg_lambda': 1.4, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:15,250] Trial 5 finished with value: 0.9630730992971769 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.925, 'reg_alpha': 0.005, 'reg_lambda': 0.9, 'min_child_weight': 3, 'gamma': 0.04, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.9}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:16,607] Trial 6 finished with value: 0.9623825843324901 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.95, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.0, 'reg_lambda': 0.8, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9500000000000001}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:17,932] Trial 7 finished with value: 0.9620380216663544 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.95, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.005, 'reg_lambda': 0.8, 'min_child_weight': 1, 'gamma': 0.02, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9500000000000001}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:19,329] Trial 8 finished with value: 0.962152831773085 and parameters: {'n_estimators': 220, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.9, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:20,331] Trial 9 finished with value: 0.9614625815002869 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.02, 'reg_lambda': 0.9, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.8}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:21,686] Trial 10 finished with value: 0.9624979238229979 and parameters: {'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.06, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0, 'reg_lambda': 1.4, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:22,882] Trial 11 finished with value: 0.9627278749013195 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8, 'colsample_bytree': 0.925, 'reg_alpha': 0.005, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.0, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.9}. Best is trial 4 with value: 0.9630730992971769.\n",
            "[I 2025-06-04 07:37:24,068] Trial 12 finished with value: 0.9634180590011455 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.005, 'reg_lambda': 1.4, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 12 with value: 0.9634180590011455.\n",
            "[I 2025-06-04 07:37:25,218] Trial 13 finished with value: 0.9633033812403594 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.4, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 12 with value: 0.9634180590011455.\n",
            "[I 2025-06-04 07:37:26,367] Trial 14 finished with value: 0.9626129986216171 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.925, 'reg_alpha': 0.015, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.1, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 12 with value: 0.9634180590011455.\n",
            "[I 2025-06-04 07:37:27,536] Trial 15 finished with value: 0.9633031827214429 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 12 with value: 0.9634180590011455.\n",
            "[I 2025-06-04 07:37:28,766] Trial 16 finished with value: 0.962037823147438 and parameters: {'n_estimators': 210, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.4, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 12 with value: 0.9634180590011455.\n",
            "[I 2025-06-04 07:37:29,879] Trial 17 finished with value: 0.9641082431009714 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 17 with value: 0.9641082431009714.\n",
            "[I 2025-06-04 07:37:30,955] Trial 18 finished with value: 0.9635327367619315 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8500000000000001}. Best is trial 17 with value: 0.9641082431009714.\n",
            "[I 2025-06-04 07:37:32,253] Trial 19 finished with value: 0.9621528979460571 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.9500000000000001}. Best is trial 17 with value: 0.9641082431009714.\n",
            "[I 2025-06-04 07:37:33,380] Trial 20 finished with value: 0.9642230532077016 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:34,497] Trial 21 finished with value: 0.9642230532077016 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:35,635] Trial 22 finished with value: 0.9635329352808479 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:36,774] Trial 23 finished with value: 0.962727676382403 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:38,030] Trial 24 finished with value: 0.9623827828514067 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.0, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:39,239] Trial 25 finished with value: 0.9613477713935564 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.3, 'min_child_weight': 1, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:40,473] Trial 26 finished with value: 0.9629582891904465 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.04, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:41,610] Trial 27 finished with value: 0.9630730331242047 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:43,013] Trial 28 finished with value: 0.9620378893204101 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.0, 'min_child_weight': 1, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:44,133] Trial 29 finished with value: 0.9612328951138538 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:45,423] Trial 30 finished with value: 0.9574369487377836 and parameters: {'n_estimators': 210, 'max_depth': 5, 'learning_rate': 0.06, 'subsample': 0.9, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 1, 'gamma': 0.04, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:46,564] Trial 31 finished with value: 0.9635329352808479 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:47,709] Trial 32 finished with value: 0.9635329352808479 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:48,814] Trial 33 finished with value: 0.962497592958137 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:50,286] Trial 34 finished with value: 0.9613476390476121 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:51,447] Trial 35 finished with value: 0.9623830475432953 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:52,545] Trial 36 finished with value: 0.9623830475432953 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.04, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 1.0}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:53,817] Trial 37 finished with value: 0.962958156844502 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.02, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:55,050] Trial 38 finished with value: 0.9592774176129953 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.05500000000000001, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 1, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:56,276] Trial 39 finished with value: 0.9636477453875785 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:57,649] Trial 40 finished with value: 0.9639933668212688 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:37:59,063] Trial 41 finished with value: 0.9621527656001128 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:00,477] Trial 42 finished with value: 0.9628429496999387 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.045000000000000005, 'subsample': 0.9, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:01,896] Trial 43 finished with value: 0.9638780935037332 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:03,264] Trial 44 finished with value: 0.9627278749013195 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.925, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:04,699] Trial 45 finished with value: 0.9630729007782604 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.95, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:06,111] Trial 46 finished with value: 0.9629577598066691 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:07,486] Trial 47 finished with value: 0.9631879094039073 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.02, 'reg_lambda': 0.9, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:08,855] Trial 48 finished with value: 0.9623827828514064 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.005, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.0, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:10,234] Trial 49 finished with value: 0.9628429496999387 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.9, 'colsample_bytree': 0.925, 'reg_alpha': 0.005, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:11,549] Trial 50 finished with value: 0.9629576936336969 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.0, 'reg_lambda': 1.3, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:12,815] Trial 51 finished with value: 0.9636481424254114 and parameters: {'n_estimators': 170, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:14,236] Trial 52 finished with value: 0.9641081107550271 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:15,597] Trial 53 finished with value: 0.9641081107550271 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:16,994] Trial 54 finished with value: 0.9624976591311093 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:18,392] Trial 55 finished with value: 0.9637632833970029 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.3, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:19,831] Trial 56 finished with value: 0.9628430158729108 and parameters: {'n_estimators': 180, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.9500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:21,358] Trial 57 finished with value: 0.9630726360863717 and parameters: {'n_estimators': 210, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.3, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:22,716] Trial 58 finished with value: 0.9629579583255856 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.04, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:24,378] Trial 59 finished with value: 0.9623828490243789 and parameters: {'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.015, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.9}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:25,563] Trial 60 finished with value: 0.9603126275897619 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.05500000000000001, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.8500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:26,929] Trial 61 finished with value: 0.9639931021293802 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:28,315] Trial 62 finished with value: 0.9639931021293802 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9500000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:29,722] Trial 63 finished with value: 0.9641081107550271 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:31,113] Trial 64 finished with value: 0.9615775901259338 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.05, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 20 with value: 0.9642230532077016.\n",
            "[I 2025-06-04 07:38:32,389] Trial 65 finished with value: 0.9645684099495033 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.005, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:33,748] Trial 66 finished with value: 0.962267906571704 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:35,045] Trial 67 finished with value: 0.9627280072472638 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.005, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:36,194] Trial 68 finished with value: 0.9635328029349036 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.005, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:37,591] Trial 69 finished with value: 0.9619229468677355 and parameters: {'n_estimators': 190, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.005, 'reg_lambda': 1.3, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:38,732] Trial 70 finished with value: 0.9635327367619315 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:40,109] Trial 71 finished with value: 0.9636480100794671 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:41,172] Trial 72 finished with value: 0.9642231193806738 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:42,295] Trial 73 finished with value: 0.963878027330761 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:43,397] Trial 74 finished with value: 0.963302918029554 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:44,449] Trial 75 finished with value: 0.9641080445820547 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:45,554] Trial 76 finished with value: 0.9626132633135057 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.9, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.005, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.06, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:46,609] Trial 77 finished with value: 0.963993035956408 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.3, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:47,693] Trial 78 finished with value: 0.9637630848780863 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:48,845] Trial 79 finished with value: 0.9624978576500256 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.95, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.005, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:50,009] Trial 80 finished with value: 0.963763018705114 and parameters: {'n_estimators': 200, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.06, 'colsample_bylevel': 0.8, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:51,053] Trial 81 finished with value: 0.9641080445820547 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:52,099] Trial 82 finished with value: 0.9641080445820547 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:53,162] Trial 83 finished with value: 0.9641080445820547 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:54,244] Trial 84 finished with value: 0.9626129324486449 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 1.0}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:55,322] Trial 85 finished with value: 0.963993035956408 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:56,581] Trial 86 finished with value: 0.9635330676267924 and parameters: {'n_estimators': 220, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.02, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:57,898] Trial 87 finished with value: 0.9621527656001128 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 0.8, 'min_child_weight': 1, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:38:59,023] Trial 88 finished with value: 0.9622677742257597 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.9}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:00,219] Trial 89 finished with value: 0.963763018705114 and parameters: {'n_estimators': 190, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.005, 'reg_lambda': 1.4, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:01,395] Trial 90 finished with value: 0.9639931683023523 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.015, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.9}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:02,588] Trial 91 finished with value: 0.9623825181595178 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:03,665] Trial 92 finished with value: 0.9641080445820547 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:04,734] Trial 93 finished with value: 0.9637629525321418 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:05,820] Trial 94 finished with value: 0.9641080445820547 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 1.0, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:06,962] Trial 95 finished with value: 0.9635328691078758 and parameters: {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.9, 'colsample_bytree': 1.0, 'reg_alpha': 0.0, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:08,008] Trial 96 finished with value: 0.9641082431009714 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:09,215] Trial 97 finished with value: 0.9627280072472638 and parameters: {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.05, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:10,593] Trial 98 finished with value: 0.9614624491543425 and parameters: {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.045000000000000005, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.1, 'colsample_bylevel': 0.9500000000000001, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "[I 2025-06-04 07:39:11,669] Trial 99 finished with value: 0.9643382603522653 and parameters: {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}. Best is trial 65 with value: 0.9645684099495033.\n",
            "🎯 Best Hyperparameters:\n",
            "{'clf__n_estimators': 180, 'clf__max_depth': 6, 'clf__learning_rate': 0.035, 'clf__subsample': 0.8, 'clf__colsample_bytree': 1.0, 'clf__reg_alpha': 0.005, 'clf__reg_lambda': 1.2000000000000002, 'clf__min_child_weight': 3, 'clf__gamma': 0.08, 'clf__colsample_bylevel': 1.0, 'clf__colsample_bynode': 0.8500000000000001}\n",
            "\n",
            "✅ Best CV Accuracy: 0.9646\n",
            "\n",
            "📊 TOP 10 CONFIGURATIONS:\n",
            "  Model  CV_Accuracy_Mean  CV_Accuracy_Std                                                                                                                                                                                                                                                                                     Hyperparameters  Rank\n",
            "XGBoost          0.964568             0.01                              {'n_estimators': 180, 'max_depth': 6, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.005, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}     1\n",
            "XGBoost          0.964338             0.01 {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.0, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}     2\n",
            "XGBoost          0.964223             0.01                  {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}     3\n",
            "XGBoost          0.964223             0.01                               {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}     4\n",
            "XGBoost          0.964223             0.01                               {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.035, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 2, 'gamma': 0.08, 'colsample_bylevel': 0.9, 'colsample_bynode': 0.8500000000000001}     5\n",
            "XGBoost          0.964108             0.01                 {'n_estimators': 170, 'max_depth': 5, 'learning_rate': 0.045000000000000005, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.1, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8}     6\n",
            "XGBoost          0.964108             0.01                 {'n_estimators': 180, 'max_depth': 5, 'learning_rate': 0.04, 'subsample': 0.8, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.02, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.08, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}     7\n",
            "XGBoost          0.964108             0.01  {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}     8\n",
            "XGBoost          0.964108             0.01  {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}     9\n",
            "XGBoost          0.964108             0.01  {'n_estimators': 170, 'max_depth': 7, 'learning_rate': 0.035, 'subsample': 0.8500000000000001, 'colsample_bytree': 0.9750000000000001, 'reg_alpha': 0.01, 'reg_lambda': 1.2000000000000002, 'min_child_weight': 3, 'gamma': 0.1, 'colsample_bylevel': 1.0, 'colsample_bynode': 0.8500000000000001}    10\n",
            "\n",
            "📈 PERFORMANCE SUMMARY:\n",
            "Total experiments: 100\n",
            "Best CV Accuracy: 0.9646\n",
            "Worst CV Accuracy: 0.9574\n",
            "Accuracy Range: 0.0071\n",
            "Total Runtime: 124.79 seconds\n",
            "\n",
            "💾 Results saved to: optuna_tpe_results.csv\n",
            "✅ Best model saved to: best_xgb_tpe_model.pkl\n",
            "\n",
            "📋 DETAILED RESULTS TABLE:\n",
            "\n",
            "💡 TPE vs Grid Search:\n",
            "   • TPE trials: 100\n",
            "   • Grid combinations: 2400 (would be ~2800)\n",
            "   • Efficiency: ~28x faster\n",
            "CPU times: user 16.4 s, sys: 623 ms, total: 17 s\n",
            "Wall time: 2min 6s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STEP 3: Model Evaluation and Test Set Performance Assessment\n",
        "This step evaluates the optimized model on the test set to assess real-world performance and generalization capability. The objective is to validate the model's effectiveness on unseen data, generate final predictions, and provide comprehensive performance metrics for deployment decision-making.\n",
        "Model Evaluation on Test Set, includes automated model selection and comprehensive performance assessment. This version includes:\n",
        "\n",
        "* Automatic detection and loading of available trained models\n",
        "* Flexible evaluation supporting both labeled and unlabeled test scenarios\n",
        "* Comprehensive metrics calculation including accuracy, F1-score, precision, recall, and AUC\n",
        "* Detailed classification analysis with confusion matrix and class-wise performance\n",
        "* Prediction probability extraction for threshold optimization\n",
        "* Consistent logging structure and CSV export for result tracking\n",
        "* Performance comparison framework for model validation against cross-validation results"
      ],
      "metadata": {
        "id": "fQwThklJjryA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# 📊 BLOCK: MODEL EVALUATION AND COMPETITION SUBMISSION\n",
        "print(\"📊 Starting Model Evaluation and Competition Submission\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 1: MODEL SELECTION AND LOADING\n",
        "# =============================================================================\n",
        "print(\"\\n🔍 Available Models:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Available model files (based on your uploads)\n",
        "available_models = [\n",
        "    {'file': 'best_xgb_model.pkl', 'name': 'XGBoost (Grid Search)'},\n",
        "    {'file': 'best_xgb_random_model.pkl', 'name': 'XGBoost (Random Search)'},\n",
        "    {'file': 'best_xgb_tpe_model.pkl', 'name': 'XGBoost (TPE)'}\n",
        "]\n",
        "\n",
        "# Auto-select first available model (or manually change index)\n",
        "selected_model = available_models[0]  # Change to [1] or [2] for other models\n",
        "print(f\"✅ Selected Model: {selected_model['name']}\")\n",
        "print(f\"📁 Model File: {selected_model['file']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cbiI5dgsBkW",
        "outputId": "b018bbe2-11af-476c-dd89-c83e43459771"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Starting Model Evaluation and Competition Submission\n",
            "============================================================\n",
            "\n",
            "🔍 Available Models:\n",
            "------------------------------\n",
            "✅ Selected Model: XGBoost (Grid Search)\n",
            "📁 Model File: best_xgb_model.pkl\n",
            "CPU times: user 140 µs, sys: 0 ns, total: 140 µs\n",
            "Wall time: 138 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# =============================================================================\n",
        "# STEP 2: LOAD COMPETITION TEST DATA\n",
        "# =============================================================================\n",
        "print(f\"\\n📥 Loading Competition Test Data\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Load competition test data\n",
        "X_comp = pd.read_csv('/content/869-spaceship-titanic/data/processed/test_dataset_spaceship_titanic_processed.csv')\n",
        "print(f\"✅ Competition test data loaded successfully\")\n",
        "print(f\"📊 Competition samples: {len(X_comp):,}\")\n",
        "\n",
        "# Save PassengerIds for submission\n",
        "passengerIDs = X_comp[\"PassengerId\"]\n",
        "print(f\"✅ Passenger IDs extracted: {len(passengerIDs):,}\")\n",
        "\n",
        "# =============================================================================\n",
        "# STEP 3: PREPROCESS COMPETITION DATA\n",
        "# =============================================================================\n",
        "print(f\"\\n🔄 Preprocessing Competition Data\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Drop PassengerId column\n",
        "X_comp = X_comp.drop(['PassengerId'], axis=1, errors='ignore')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov4vfWQzsHNm",
        "outputId": "210ce031-8beb-406f-acd3-bf50ec91e6ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📥 Loading Competition Test Data\n",
            "----------------------------------------\n",
            "✅ Competition test data loaded successfully\n",
            "📊 Competition samples: 4,277\n",
            "✅ Passenger IDs extracted: 4,277\n",
            "\n",
            "🔄 Preprocessing Competition Data\n",
            "----------------------------------------\n",
            "CPU times: user 56.2 ms, sys: 0 ns, total: 56.2 ms\n",
            "Wall time: 56 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 4: LOAD MODEL AND GENERATE PREDICTIONS\n",
        "# =============================================================================\n",
        "print(f\"\\n🔄 Loading Model and Generating Predictions\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "# Load the model\n",
        "best_model = joblib.load(selected_model['file'])\n",
        "print(f\"✅ Model loaded successfully\")\n",
        "\n",
        "# Generate predictions on competition test set\n",
        "pred_comp = best_model.predict(X_comp)\n",
        "pred_proba_comp = best_model.predict_proba(X_comp)\n",
        "\n",
        "prediction_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "print(f\"✅ Predictions generated successfully\")\n",
        "print(f\"📊 Competition samples: {len(X_comp):,}\")\n",
        "print(f\"⏱️  Prediction time: {prediction_time:.3f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWgP98rPjq-1",
        "outputId": "77e088ca-34b0-4677-bd3d-21868ba93153"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Loading Model and Generating Predictions\n",
            "----------------------------------------\n",
            "✅ Model loaded successfully\n",
            "✅ Predictions generated successfully\n",
            "📊 Competition samples: 4,277\n",
            "⏱️  Prediction time: 0.100 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 4: ANALYZE PREDICTIONS\n",
        "# =============================================================================\n",
        "print(f\"\\n📊 Prediction Analysis:\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"🎯 Model: {selected_model['name']}\")\n",
        "print(f\"📊 Total predictions: {len(pred_comp):,}\")\n",
        "print(f\"📊 Predicted class 0 (Not Transported): {(pred_comp == 0).sum():,} ({(pred_comp == 0).mean():.1%})\")\n",
        "print(f\"📊 Predicted class 1 (Transported): {(pred_comp == 1).sum():,} ({(pred_comp == 1).mean():.1%})\")\n",
        "print(f\"📊 Mean prediction probability: {pred_proba_comp[:, 1].mean():.3f}\")\n",
        "print(f\"📊 Prediction confidence (max prob): {pred_proba_comp.max(axis=1).mean():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HktuE3i4setm",
        "outputId": "b90cc1ab-72b9-4f2a-9a0a-de369e926d2c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Prediction Analysis:\n",
            "----------------------------------------\n",
            "🎯 Model: XGBoost (Grid Search)\n",
            "📊 Total predictions: 4,277\n",
            "📊 Predicted class 0 (Not Transported): 2,007 (46.9%)\n",
            "📊 Predicted class 1 (Transported): 2,270 (53.1%)\n",
            "📊 Mean prediction probability: 0.502\n",
            "📊 Prediction confidence (max prob): 0.657\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 5: CREATE SUBMISSION FILE\n",
        "# =============================================================================\n",
        "print(f\"\\n💾 Creating Submission File\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Create submission dataframe\n",
        "my_submission = pd.DataFrame({\n",
        "    'PassengerId': passengerIDs,\n",
        "    'Transported': pred_comp.astype(bool)  # Convert to boolean as required by competition\n",
        "})\n",
        "\n",
        "# Display first 10 rows as sanity check\n",
        "print(f\"📋 Submission Preview:\")\n",
        "print(my_submission.head(10))\n",
        "\n",
        "# Save submission file\n",
        "submission_filename = f'submission_{selected_model[\"name\"].lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.csv'\n",
        "my_submission.to_csv(submission_filename, index=False)\n",
        "print(f\"✅ Submission saved to: {submission_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeaRN6RSsgSD",
        "outputId": "c235c1a2-cc82-4e34-90fb-2be2d373cd49"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Creating Submission File\n",
            "------------------------------\n",
            "📋 Submission Preview:\n",
            "   PassengerId  Transported\n",
            "0            0         True\n",
            "1            1         True\n",
            "2            2         True\n",
            "3            3         True\n",
            "4            4         True\n",
            "5            5         True\n",
            "6            6         True\n",
            "7            7         True\n",
            "8            8         True\n",
            "9            9         True\n",
            "✅ Submission saved to: submission_xgboost_grid_search.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 6: SAVE DETAILED PREDICTIONS (OPTIONAL)\n",
        "# =============================================================================\n",
        "print(f\"\\n💾 Saving Detailed Predictions\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "# Create detailed predictions dataframe\n",
        "detailed_predictions = pd.DataFrame({\n",
        "    'PassengerId': passengerIDs,\n",
        "    'Predicted_Label': pred_comp,\n",
        "    'Prediction_Probability_Not_Transported': pred_proba_comp[:, 0],\n",
        "    'Prediction_Probability_Transported': pred_proba_comp[:, 1],\n",
        "    'Prediction_Confidence': pred_proba_comp.max(axis=1)\n",
        "})\n",
        "\n",
        "detailed_filename = f'detailed_predictions_{selected_model[\"name\"].lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")}.csv'\n",
        "detailed_predictions.to_csv(detailed_filename, index=False)\n",
        "print(f\"✅ Detailed predictions saved to: {detailed_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMy3pcPOskaz",
        "outputId": "f9a6c3a0-66fe-460c-8648-51df0ac666e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "💾 Saving Detailed Predictions\n",
            "-----------------------------------\n",
            "✅ Detailed predictions saved to: detailed_predictions_xgboost_grid_search.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 7: NOTE ABOUT TEST SET\n",
        "# =============================================================================\n",
        "print(f\"\\n📝 Important Note About Test Set\")\n",
        "print(\"-\" * 40)\n",
        "print(\"ℹ️  The competition test set has NO labels (no 'Transported' column)\")\n",
        "print(\"ℹ️  This is the unlabeled data you need to predict for submission\")\n",
        "print(\"ℹ️  True performance will only be known after Kaggle submission\")\n",
        "print(\"ℹ️  Use cross-validation scores from training as performance estimates\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnevJeATsoFI",
        "outputId": "2f88c143-17b0-4984-cf4c-605068519eb5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📝 Important Note About Test Set\n",
            "----------------------------------------\n",
            "ℹ️  The competition test set has NO labels (no 'Transported' column)\n",
            "ℹ️  This is the unlabeled data you need to predict for submission\n",
            "ℹ️  True performance will only be known after Kaggle submission\n",
            "ℹ️  Use cross-validation scores from training as performance estimates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# STEP 8: SUMMARY\n",
        "# =============================================================================\n",
        "end_time = datetime.now()\n",
        "total_runtime = (end_time - start_time).total_seconds()\n",
        "\n",
        "print(f\"\\n📈 EVALUATION SUMMARY\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"✅ Model: {selected_model['name']}\")\n",
        "print(f\"📁 Model File: {selected_model['file']}\")\n",
        "print(f\"🔮 Competition Samples: {len(X_comp):,}\")\n",
        "print(f\"⏱️  Total Runtime: {total_runtime:.2f} seconds\")\n",
        "\n",
        "print(f\"\\n📊 Files Generated:\")\n",
        "print(f\"   • {submission_filename} (Main submission file)\")\n",
        "print(f\"   • {detailed_filename} (Detailed predictions)\")\n",
        "\n",
        "print(f\"\\n🚀 Next Steps:\")\n",
        "print(f\"   1. Upload '{submission_filename}' to Kaggle competition\")\n",
        "print(f\"   2. Check leaderboard performance\")\n",
        "print(f\"   3. Compare with cross-validation scores from training\")\n",
        "print(f\"   4. Consider ensemble methods if performance differs significantly\")\n",
        "\n",
        "print(f\"\\n✅ Model evaluation and submission preparation completed successfully!\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qkvRGrtso-i",
        "outputId": "0750d777-97a8-403a-ea1f-297c30ad5f76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📈 EVALUATION SUMMARY\n",
            "========================================\n",
            "✅ Model: XGBoost (Grid Search)\n",
            "📁 Model File: best_xgb_model.pkl\n",
            "🔮 Competition Samples: 4,277\n",
            "⏱️  Total Runtime: 0.15 seconds\n",
            "\n",
            "📊 Files Generated:\n",
            "   • submission_xgboost_grid_search.csv (Main submission file)\n",
            "   • detailed_predictions_xgboost_grid_search.csv (Detailed predictions)\n",
            "\n",
            "🚀 Next Steps:\n",
            "   1. Upload 'submission_xgboost_grid_search.csv' to Kaggle competition\n",
            "   2. Check leaderboard performance\n",
            "   3. Compare with cross-validation scores from training\n",
            "   4. Consider ensemble methods if performance differs significantly\n",
            "\n",
            "✅ Model evaluation and submission preparation completed successfully!\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}